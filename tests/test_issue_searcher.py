"""
ì´ìŠˆ ê²€ìƒ‰ê¸° pytest í…ŒìŠ¤íŠ¸ - 4ë‹¨ê³„ ì„¸ë¶€ ì •ë³´ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ í¬í•¨ (ìˆ˜ì •ë¨)
"""

import pytest
import sys
import os
from unittest.mock import patch, MagicMock, AsyncMock
import asyncio
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì˜ src í´ë”ë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
src_path = os.path.join(project_root, 'src')
sys.path.insert(0, src_path)


class TestStage4DataClasses:
    """4ë‹¨ê³„ ë°ì´í„° í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    def test_entity_info_creation(self):
        """EntityInfo ë°ì´í„°í´ë˜ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import EntityInfo

        entity = EntityInfo(
            name="ì—˜ë¡  ë¨¸ìŠ¤í¬",
            role="Tesla CEO",
            relevance=0.9,
            entity_type="person",
            description="ì „ê¸°ì°¨ ë° ìš°ì£¼ ì‚°ì—… ë¦¬ë”"
        )

        assert entity.name == "ì—˜ë¡  ë¨¸ìŠ¤í¬"
        assert entity.role == "Tesla CEO"
        assert entity.relevance == 0.9
        assert entity.entity_type == "person"
        assert entity.description == "ì „ê¸°ì°¨ ë° ìš°ì£¼ ì‚°ì—… ë¦¬ë”"

    @pytest.mark.unit
    def test_impact_analysis_creation(self):
        """ImpactAnalysis ë°ì´í„°í´ë˜ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import ImpactAnalysis

        impact = ImpactAnalysis(
            impact_level="high",
            impact_score=0.8,
            affected_sectors=["ê¸°ìˆ ", "ìë™ì°¨"],
            geographic_scope="global",
            time_sensitivity="short-term",
            reasoning="ì „ê¸°ì°¨ ì‹œì¥ì— ëŒ€í•œ ê¸€ë¡œë²Œ ì˜í–¥"
        )

        assert impact.impact_level == "high"
        assert impact.impact_score == 0.8
        assert impact.affected_sectors == ["ê¸°ìˆ ", "ìë™ì°¨"]
        assert impact.geographic_scope == "global"
        assert impact.time_sensitivity == "short-term"
        assert impact.reasoning == "ì „ê¸°ì°¨ ì‹œì¥ì— ëŒ€í•œ ê¸€ë¡œë²Œ ì˜í–¥"

    @pytest.mark.unit
    def test_timeline_event_creation(self):
        """TimelineEvent ë°ì´í„°í´ë˜ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import TimelineEvent

        event = TimelineEvent(
            date="2024-01-15",
            event_type="announcement",
            description="ìƒˆë¡œìš´ ì „ê¸°ì°¨ ëª¨ë¸ ë°œí‘œ",
            importance=0.9,
            source="Tesla Press Release"
        )

        assert event.date == "2024-01-15"
        assert event.event_type == "announcement"
        assert event.description == "ìƒˆë¡œìš´ ì „ê¸°ì°¨ ëª¨ë¸ ë°œí‘œ"
        assert event.importance == 0.9
        assert event.source == "Tesla Press Release"

    @pytest.mark.unit
    def test_enhanced_issue_item(self):
        """í™•ì¥ëœ IssueItem í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueItem, EntityInfo, ImpactAnalysis, TimelineEvent

        entity = EntityInfo("í…ŒìŠ¤íŠ¸", "ì—­í• ", 0.5, "person", "ì„¤ëª…")
        impact = ImpactAnalysis("medium", 0.6, ["ê¸°ìˆ "], "national", "short-term", "ì´ìœ ")
        timeline = TimelineEvent("2024-01-01", "development", "ì„¤ëª…", 0.7, "ì¶œì²˜")

        issue = IssueItem(
            title="í…ŒìŠ¤íŠ¸ ì´ìŠˆ",
            summary="í…ŒìŠ¤íŠ¸ ìš”ì•½",
            source="í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤",
            published_date="2024-01-15",
            relevance_score=0.85,
            category="news",
            content_snippet="í…ŒìŠ¤íŠ¸ ë‚´ìš©",
            detailed_content="ìƒì„¸ ë‚´ìš©",
            related_entities=[entity],
            impact_analysis=impact,
            timeline_events=[timeline],
            background_context="ë°°ê²½ ì •ë³´",
            detail_collection_time=2.5,
            detail_confidence=0.8
        )

        assert issue.detailed_content == "ìƒì„¸ ë‚´ìš©"
        assert len(issue.related_entities) == 1
        assert issue.impact_analysis.impact_level == "medium"
        assert len(issue.timeline_events) == 1
        assert issue.background_context == "ë°°ê²½ ì •ë³´"
        assert issue.detail_collection_time == 2.5
        assert issue.detail_confidence == 0.8

    @pytest.mark.unit
    def test_enhanced_search_result(self):
        """í™•ì¥ëœ SearchResult í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import SearchResult

        result = SearchResult(
            query_keywords=["AI", "ê¸°ìˆ "],
            total_found=5,
            issues=[],
            search_time=3.0,
            api_calls_used=3,
            confidence_score=0.8,
            time_period="ìµœê·¼ 1ì£¼ì¼",
            raw_responses=["response1"],
            detailed_issues_count=2,
            total_detail_collection_time=15.0,
            average_detail_confidence=0.75
        )

        assert result.detailed_issues_count == 2
        assert result.total_detail_collection_time == 15.0
        assert result.average_detail_confidence == 0.75


class TestStage4PerplexityClient:
    """4ë‹¨ê³„ Perplexity í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_perplexity_key'})
    def test_perplexity_client_stage4_methods(self):
        """Perplexity í´ë¼ì´ì–¸íŠ¸ 4ë‹¨ê³„ ë©”ì„œë“œ ì¡´ì¬ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import PerplexityClient

        client = PerplexityClient(api_key="test_key")

        # 4ë‹¨ê³„ ë©”ì„œë“œë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        assert hasattr(client, 'collect_detailed_information')
        assert hasattr(client, 'extract_entities_and_impact')
        assert hasattr(client, 'extract_timeline')
        assert hasattr(client, '_make_api_call')

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_collect_detailed_information(self):
        """ì„¸ë¶€ ì •ë³´ ìˆ˜ì§‘ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
        mock_response = {
            "choices": [{
                "message": {
                    "content": """**ìƒì„¸ ë‚´ìš©**: AI ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ëŒ€í™”í˜• AIì˜ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
**ê´€ë ¨ ì¸ë¬¼/ê¸°ê´€**: OpenAI, Google, Meta ë“±ì´ ì£¼ìš” ê°œë°œì‚¬ì…ë‹ˆë‹¤.
**ì˜í–¥ë„ ë¶„ì„**: ê¸°ìˆ  ì‚°ì—… ì „ë°˜ì— í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."""
                }
            }]
        }

        with patch('src.issue_searcher.httpx.AsyncClient') as mock_client:
            mock_response_obj = MagicMock()
            mock_response_obj.status_code = 200
            mock_response_obj.json.return_value = mock_response

            mock_context = AsyncMock()
            mock_context.__aenter__.return_value.post.return_value = mock_response_obj
            mock_client.return_value = mock_context

            from src.issue_searcher import PerplexityClient

            client = PerplexityClient(api_key="test_key")
            result = await client.collect_detailed_information(
                "AI ê¸°ìˆ  ë°œì „",
                "AIê°€ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆë‹¤",
                ["AI", "ê¸°ìˆ "]
            )

            assert "choices" in result
            assert "AI ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ" in result["choices"][0]["message"]["content"]


class TestStage4IssueSearcher:
    """4ë‹¨ê³„ IssueSearcher í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_perplexity_key'})
    def test_issue_searcher_stage4_initialization(self):
        """4ë‹¨ê³„ IssueSearcher ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        searcher = IssueSearcher(api_key="test_key")

        # 4ë‹¨ê³„ ê´€ë ¨ ì†ì„±ë“¤ í™•ì¸
        assert hasattr(searcher, 'enable_detailed_collection')
        assert hasattr(searcher, 'max_detailed_issues')
        assert hasattr(searcher, 'detail_collection_timeout')

        assert searcher.enable_detailed_collection == True
        assert searcher.max_detailed_issues == 10
        assert searcher.detail_collection_timeout == 60

    @pytest.mark.unit
    def test_calculate_detail_confidence(self):
        """ì„¸ë¶€ ì •ë³´ ì‹ ë¢°ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher, EntityInfo, ImpactAnalysis, TimelineEvent

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            detailed_content = "ì´ê²ƒì€ ì¶©ë¶„íˆ ê¸´ ìƒì„¸ ë‚´ìš©ì…ë‹ˆë‹¤. " * 10

            entities = [
                EntityInfo("OpenAI", "AI íšŒì‚¬", 0.9, "company", "ChatGPT ê°œë°œ"),
                EntityInfo("Sam Altman", "CEO", 0.8, "person", "OpenAI CEO")
            ]

            impact = ImpactAnalysis(
                "high", 0.8, ["ê¸°ìˆ ", "êµìœ¡"], "global", "short-term", "AI í™•ì‚°"
            )

            timeline_events = [
                TimelineEvent("2024-01-01", "announcement", "ë°œí‘œ", 0.9, "ì¶œì²˜1"),
                TimelineEvent("2024-01-02", "development", "ê°œë°œ", 0.8, "ì¶œì²˜2")
            ]

            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = searcher._calculate_detail_confidence(
                detailed_content, entities, impact, timeline_events
            )

            # ë†’ì€ ì‹ ë¢°ë„ ê¸°ëŒ€ (ëª¨ë“  ìš”ì†Œê°€ ì¶©ì¡±ë¨)
            assert confidence > 0.8
            assert confidence <= 1.0

    @pytest.mark.unit
    def test_extract_detailed_content(self):
        """ìƒì„¸ ë‚´ìš© ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            # í…ŒìŠ¤íŠ¸ API ì‘ë‹µ
            api_response = {
                "choices": [{
                    "message": {
                        "content": """ë‹¤ìŒì€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

**ìƒì„¸ ë‚´ìš©**: AI ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ëŒ€í™”í˜• AIì˜ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚°ì—… ì „ë°˜ì— í° ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

**ê´€ë ¨ ì¸ë¬¼/ê¸°ê´€**: OpenAI, Google ë“±"""
                    }
                }]
            }

            detailed_content = searcher._extract_detailed_content(api_response)

            assert "AI ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ" in detailed_content
            assert "ëŒ€í™”í˜• AIì˜ ì„±ëŠ¥" in detailed_content

    @pytest.mark.unit
    def test_parse_entity_and_impact_response(self):
        """ì—”í‹°í‹° ë° ì˜í–¥ë„ ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            # JSON ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
            response = {
                "choices": [{
                    "message": {
                        "content": """{
    "entities": [
        {
            "name": "OpenAI",
            "role": "AI ê°œë°œ íšŒì‚¬", 
            "relevance": 0.9,
            "entity_type": "company",
            "description": "ChatGPT ê°œë°œì‚¬"
        }
    ],
    "impact": {
        "impact_level": "high",
        "impact_score": 0.8,
        "affected_sectors": ["ê¸°ìˆ ", "êµìœ¡"],
        "geographic_scope": "global",
        "time_sensitivity": "short-term",
        "reasoning": "AI ê¸°ìˆ ì˜ ê¸‰ì†í•œ ë°œì „"
    }
}"""
                    }
                }]
            }

            entities, impact = searcher._parse_entity_and_impact_response(response)

            # ì—”í‹°í‹° ê²€ì¦
            assert len(entities) == 1
            assert entities[0].name == "OpenAI"
            assert entities[0].relevance == 0.9
            assert entities[0].entity_type == "company"

            # ì˜í–¥ë„ ê²€ì¦
            assert impact is not None
            assert impact.impact_level == "high"
            assert impact.impact_score == 0.8
            assert "ê¸°ìˆ " in impact.affected_sectors
            assert impact.geographic_scope == "global"

    @pytest.mark.unit
    def test_parse_timeline_response(self):
        """íƒ€ì„ë¼ì¸ ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            response = {
                "choices": [{
                    "message": {
                        "content": """{
    "timeline": [
        {
            "date": "2024-01-15",
            "event_type": "announcement",
            "description": "ìƒˆë¡œìš´ AI ëª¨ë¸ ë°œí‘œ",
            "importance": 0.9,
            "source": "OpenAI Blog"
        },
        {
            "date": "2024-01-20",
            "event_type": "development",
            "description": "ê¸°ëŠ¥ ì—…ë°ì´íŠ¸",
            "importance": 0.7,
            "source": "Tech News"
        }
    ],
    "background_context": "AI ê¸°ìˆ  ë°œì „ì˜ ë°°ê²½ ì •ë³´ì…ë‹ˆë‹¤."
}"""
                    }
                }]
            }

            timeline_events, background_context = searcher._parse_timeline_response(response)

            # íƒ€ì„ë¼ì¸ ê²€ì¦
            assert len(timeline_events) == 2
            assert timeline_events[0].date == "2024-01-15"
            assert timeline_events[0].event_type == "announcement"
            assert timeline_events[0].importance == 0.9
            assert timeline_events[1].description == "ê¸°ëŠ¥ ì—…ë°ì´íŠ¸"

            # ë°°ê²½ ì •ë³´ ê²€ì¦
            assert "AI ê¸°ìˆ  ë°œì „ì˜ ë°°ê²½" in background_context

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_collect_issue_details(self):
        """ì´ìŠˆ ì„¸ë¶€ ì •ë³´ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher, IssueItem

        # Mock API ì‘ë‹µë“¤ ì¤€ë¹„
        detailed_response = {
            "choices": [{
                "message": {
                    "content": "**ìƒì„¸ ë‚´ìš©**: AI ê¸°ìˆ  ë°œì „ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©ì…ë‹ˆë‹¤."
                }
            }]
        }

        entity_response = {
            "choices": [{
                "message": {
                    "content": '{"entities": [{"name": "OpenAI", "role": "AI íšŒì‚¬", "relevance": 0.9, "entity_type": "company", "description": "ChatGPT ê°œë°œ"}], "impact": {"impact_level": "high", "impact_score": 0.8, "affected_sectors": ["ê¸°ìˆ "], "geographic_scope": "global", "time_sensitivity": "short-term", "reasoning": "AI í™•ì‚°"}}'
                }
            }]
        }

        timeline_response = {
            "choices": [{
                "message": {
                    "content": '{"timeline": [{"date": "2024-01-15", "event_type": "announcement", "description": "ë°œí‘œ", "importance": 0.9, "source": "ì¶œì²˜"}], "background_context": "ë°°ê²½ ì •ë³´"}'
                }
            }]
        }

        with patch('src.issue_searcher.PerplexityClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.collect_detailed_information.return_value = detailed_response
            mock_client.extract_entities_and_impact.return_value = entity_response
            mock_client.extract_timeline.return_value = timeline_response
            mock_client_class.return_value = mock_client

            searcher = IssueSearcher(api_key="test_key")

            # í…ŒìŠ¤íŠ¸ìš© ì´ìŠˆ ì•„ì´í…œ
            issue = IssueItem(
                title="AI ê¸°ìˆ  ë°œì „",
                summary="AIê°€ ë°œì „í•˜ê³  ìˆë‹¤",
                source="Tech News",
                published_date="2024-01-15",
                relevance_score=0.8,
                category="news",
                content_snippet="AI ë°œì „",
                related_entities=[],
                timeline_events=[]
            )

            # ì„¸ë¶€ ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰
            enhanced_issue = await searcher._collect_issue_details(issue, ["AI", "ê¸°ìˆ "])

            # ê²°ê³¼ ê²€ì¦
            assert enhanced_issue.detailed_content is not None
            assert "AI ê¸°ìˆ  ë°œì „ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©" in enhanced_issue.detailed_content
            assert len(enhanced_issue.related_entities) == 1
            assert enhanced_issue.related_entities[0].name == "OpenAI"
            assert enhanced_issue.impact_analysis is not None
            assert enhanced_issue.impact_analysis.impact_level == "high"
            assert len(enhanced_issue.timeline_events) == 1
            assert enhanced_issue.timeline_events[0].description == "ë°œí‘œ"
            assert enhanced_issue.background_context == "ë°°ê²½ ì •ë³´"
            assert enhanced_issue.detail_confidence > 0.0

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_search_issues_with_details_fixed(self):
        """ì„¸ë¶€ ì •ë³´ í¬í•¨ ì´ìŠˆ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸ - ìˆ˜ì •ë¨"""
        # ê¸°ë³¸ ê²€ìƒ‰ ì‘ë‹µ
        basic_search_response = {
            "choices": [{
                "message": {
                    "content": """**ì œëª©**: AI ê¸°ìˆ  í˜ì‹ 
**ìš”ì•½**: AI ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: Tech Journal
**ì¼ì**: 2024-01-15
**ì¹´í…Œê³ ë¦¬**: news

**ì œëª©**: ë¨¸ì‹ ëŸ¬ë‹ ë°œì „
**ìš”ì•½**: ìƒˆë¡œìš´ ML ì•Œê³ ë¦¬ì¦˜ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: AI Magazine
**ì¼ì**: 2024-01-14
**ì¹´í…Œê³ ë¦¬**: academic"""
                }
            }]
        }

        # ì„¸ë¶€ ì •ë³´ ì‘ë‹µë“¤
        detailed_response = {
            "choices": [{
                "message": {
                    "content": "**ìƒì„¸ ë‚´ìš©**: AI ê¸°ìˆ ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤."
                }
            }]
        }

        entity_response = {
            "choices": [{
                "message": {
                    "content": '{"entities": [{"name": "OpenAI", "role": "AI íšŒì‚¬", "relevance": 0.9, "entity_type": "company", "description": "AI ê°œë°œ"}], "impact": {"impact_level": "medium", "impact_score": 0.7, "affected_sectors": ["ê¸°ìˆ "], "geographic_scope": "global", "time_sensitivity": "short-term", "reasoning": "ê¸°ìˆ  ë°œì „"}}'
                }
            }]
        }

        timeline_response = {
            "choices": [{
                "message": {
                    "content": '{"timeline": [{"date": "2024-01-15", "event_type": "announcement", "description": "ë°œí‘œ", "importance": 0.8, "source": "ì¶œì²˜"}], "background_context": "ë°°ê²½"}'
                }
            }]
        }

        with patch('src.issue_searcher.PerplexityClient') as mock_client_class:
            mock_client = AsyncMock()

            # ì§ì ‘ ë©”ì„œë“œë³„ë¡œ Mock ì„¤ì •
            mock_client.search_issues.return_value = basic_search_response
            mock_client.collect_detailed_information.return_value = detailed_response
            mock_client.extract_entities_and_impact.return_value = entity_response
            mock_client.extract_timeline.return_value = timeline_response

            mock_client_class.return_value = mock_client

            from src.issue_searcher import IssueSearcher
            from src.keyword_generator import KeywordResult

            keyword_result = KeywordResult(
                topic="AI ê¸°ìˆ ",
                primary_keywords=["AI", "ì¸ê³µì§€ëŠ¥"],
                related_terms=["ë¨¸ì‹ ëŸ¬ë‹"],
                synonyms=["ê¸°ê³„í•™ìŠµ"],
                context_keywords=["ê¸°ìˆ í˜ì‹ "],
                confidence_score=0.8,
                generation_time=1.0,
                raw_response="test"
            )

            searcher = IssueSearcher(api_key="test_key")
            result = await searcher.search_issues_from_keywords(
                keyword_result,
                collect_details=True
            )

            # ê²°ê³¼ ê²€ì¦
            assert result.total_found >= 1
            assert result.detailed_issues_count >= 1
            assert result.average_detail_confidence > 0.0
            assert result.total_detail_collection_time > 0.0

            # ì²« ë²ˆì§¸ ì´ìŠˆì˜ ì„¸ë¶€ ì •ë³´ í™•ì¸
            if result.issues:
                first_issue = result.issues[0]
                if first_issue.detailed_content:
                    assert first_issue.detailed_content is not None
                    assert first_issue.detail_confidence > 0.0


class TestStage4ConvenienceFunctions:
    """4ë‹¨ê³„ í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_key'})
    def test_search_issues_for_keywords_with_details(self):
        """ì„¸ë¶€ ì •ë³´ í¬í•¨ í‚¤ì›Œë“œ ê²€ìƒ‰ í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import search_issues_for_keywords

        # í•¨ìˆ˜ê°€ collect_details íŒŒë¼ë¯¸í„°ë¥¼ ë°›ëŠ”ì§€ í™•ì¸
        import inspect
        sig = inspect.signature(search_issues_for_keywords)
        assert 'collect_details' in sig.parameters

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_key'})
    def test_create_detailed_report_from_search_result(self):
        """ìƒì„¸ ë³´ê³ ì„œ ìƒì„± í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import create_detailed_report_from_search_result, SearchResult, IssueItem, EntityInfo, ImpactAnalysis

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
        entity = EntityInfo("OpenAI", "AI íšŒì‚¬", 0.9, "company", "ChatGPT ê°œë°œ")
        impact = ImpactAnalysis("high", 0.8, ["ê¸°ìˆ "], "global", "short-term", "AI í™•ì‚°")

        issue = IssueItem(
            title="AI ê¸°ìˆ  í˜ì‹ ",
            summary="AI ê¸°ìˆ ì´ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤",
            source="Tech News",
            published_date="2024-01-15",
            relevance_score=0.9,
            category="news",
            content_snippet="AI ë°œì „",
            detailed_content="AI ê¸°ìˆ ì— ëŒ€í•œ ìƒì„¸í•œ ë‚´ìš©ì…ë‹ˆë‹¤.",
            related_entities=[entity],
            impact_analysis=impact,
            timeline_events=[],
            background_context="ë°°ê²½ ì •ë³´",
            detail_confidence=0.85
        )

        search_result = SearchResult(
            query_keywords=["AI", "ê¸°ìˆ "],
            total_found=1,
            issues=[issue],
            search_time=3.0,
            api_calls_used=3,
            confidence_score=0.8,
            time_period="ìµœê·¼ 1ì£¼ì¼",
            raw_responses=["test"],
            detailed_issues_count=1,
            total_detail_collection_time=5.0,
            average_detail_confidence=0.85
        )

        # ë³´ê³ ì„œ ìƒì„±
        report = create_detailed_report_from_search_result(search_result)

        # ë³´ê³ ì„œ ë‚´ìš© ê²€ì¦
        assert "ì¢…í•© ì´ìŠˆ ë¶„ì„ ë³´ê³ ì„œ" in report
        assert "AI ê¸°ìˆ  í˜ì‹ " in report
        assert "OpenAI" in report
        assert "high" in report
        assert "ì„¸ë¶€ ë¶„ì„ ì´ìŠˆ" in report and "1ê°œ" in report

    @pytest.mark.unit
    def test_format_detailed_issue_report(self):
        """ê°œë³„ ì´ìŠˆ ìƒì„¸ ë³´ê³ ì„œ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import create_issue_searcher, IssueItem, EntityInfo, ImpactAnalysis, TimelineEvent

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = create_issue_searcher(api_key="test_key")

            # í…ŒìŠ¤íŠ¸ ë°ì´í„°
            entity = EntityInfo("ì—˜ë¡  ë¨¸ìŠ¤í¬", "Tesla CEO", 0.9, "person", "ì „ê¸°ì°¨ ë¦¬ë”")
            impact = ImpactAnalysis("high", 0.8, ["ìë™ì°¨", "ê¸°ìˆ "], "global", "short-term", "ì „ê¸°ì°¨ í˜ì‹ ")
            timeline_event = TimelineEvent("2024-01-15", "announcement", "ìƒˆ ëª¨ë¸ ë°œí‘œ", 0.9, "Tesla")

            issue = IssueItem(
                title="Tesla ì‹ ëª¨ë¸ ë°œí‘œ",
                summary="Teslaê°€ ìƒˆë¡œìš´ ì „ê¸°ì°¨ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤",
                source="Tesla Blog",
                published_date="2024-01-15",
                relevance_score=0.9,
                category="news",
                content_snippet="Tesla ì‹ ëª¨ë¸",
                detailed_content="Teslaì˜ ìƒˆë¡œìš´ ì „ê¸°ì°¨ ëª¨ë¸ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ì…ë‹ˆë‹¤.",
                related_entities=[entity],
                impact_analysis=impact,
                timeline_events=[timeline_event],
                background_context="ì „ê¸°ì°¨ ì‹œì¥ ë°œì „ ë°°ê²½",
                detail_confidence=0.88
            )

            # ë³´ê³ ì„œ ìƒì„±
            report = searcher.format_detailed_issue_report(issue)

            # ë‚´ìš© ê²€ì¦
            assert "Tesla ì‹ ëª¨ë¸ ë°œí‘œ" in report
            assert "ì—˜ë¡  ë¨¸ìŠ¤í¬" in report
            assert "ğŸ‘¤" in report  # person emoji
            assert "ğŸŸ " in report  # high impact emoji
            assert "ğŸ“¢" in report  # announcement emoji
            assert "ì „ê¸°ì°¨ ì‹œì¥ ë°œì „ ë°°ê²½" in report
            assert "88%" in report  # detail confidence


class TestStage4Integration:
    """4ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_full_stage4_pipeline(self):
        """4ë‹¨ê³„ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        # ë³µí•©ì ì¸ Mock ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
        search_response = {
            "choices": [{
                "message": {
                    "content": """**ì œëª©**: OpenAI GPT-4 ì—…ë°ì´íŠ¸
**ìš”ì•½**: OpenAIê°€ GPT-4ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: OpenAI Blog
**ì¼ì**: 2024-01-15
**ì¹´í…Œê³ ë¦¬**: news"""
                }
            }]
        }

        detail_response = {
            "choices": [{
                "message": {
                    "content": "**ìƒì„¸ ë‚´ìš©**: GPT-4ì˜ ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ê³¼ í–¥ìƒëœ ì¶”ë¡  ëŠ¥ë ¥ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤."
                }
            }]
        }

        entity_response = {
            "choices": [{
                "message": {
                    "content": '{"entities": [{"name": "Sam Altman", "role": "OpenAI CEO", "relevance": 0.95, "entity_type": "person", "description": "OpenAI ìµœê³ ê²½ì˜ì"}], "impact": {"impact_level": "high", "impact_score": 0.9, "affected_sectors": ["ê¸°ìˆ ", "êµìœ¡", "ì—”í„°í…Œì¸ë¨¼íŠ¸"], "geographic_scope": "global", "time_sensitivity": "immediate", "reasoning": "AI ê¸°ìˆ ì˜ ê¸‰ì§„ì  ë°œì „"}, "confidence": 0.9}'
                }
            }]
        }

        timeline_response = {
            "choices": [{
                "message": {
                    "content": '{"timeline": [{"date": "2024-01-10", "event_type": "development", "description": "GPT-4 ì—…ë°ì´íŠ¸ ê°œë°œ ì™„ë£Œ", "importance": 0.8, "source": "ë‚´ë¶€ ì •ë³´"}, {"date": "2024-01-15", "event_type": "announcement", "description": "ê³µì‹ ë°œí‘œ", "importance": 1.0, "source": "OpenAI Blog"}], "background_context": "OpenAIëŠ” ì§€ì†ì ìœ¼ë¡œ GPT ëª¨ë¸ì„ ê°œì„ í•´ì™”ìœ¼ë©°, ì´ë²ˆ ì—…ë°ì´íŠ¸ëŠ” ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤."}'
                }
            }]
        }

        with patch('src.issue_searcher.PerplexityClient') as mock_client_class:
            mock_client = AsyncMock()

            # ê° ë©”ì„œë“œë³„ë¡œ ì§ì ‘ Mock ì„¤ì •
            mock_client.search_issues.return_value = search_response
            mock_client.collect_detailed_information.return_value = detail_response
            mock_client.extract_entities_and_impact.return_value = entity_response
            mock_client.extract_timeline.return_value = timeline_response

            mock_client_class.return_value = mock_client

            from src.issue_searcher import IssueSearcher
            from src.keyword_generator import KeywordResult

            # í‚¤ì›Œë“œ ê²°ê³¼ ì¤€ë¹„
            keyword_result = KeywordResult(
                topic="OpenAI GPT-4 ì—…ë°ì´íŠ¸",
                primary_keywords=["OpenAI", "GPT-4", "AI"],
                related_terms=["ë©€í‹°ëª¨ë‹¬", "ì¶”ë¡ "],
                synonyms=["ì¸ê³µì§€ëŠ¥", "ì–¸ì–´ëª¨ë¸"],
                context_keywords=["ê¸°ìˆ í˜ì‹ ", "ìì—°ì–´ì²˜ë¦¬"],
                confidence_score=0.9,
                generation_time=2.0,
                raw_response="test response"
            )

            # 4ë‹¨ê³„ ì „ì²´ ì‹¤í–‰
            searcher = IssueSearcher(api_key="test_key")
            result = await searcher.search_issues_from_keywords(
                keyword_result,
                time_period="ìµœê·¼ 1ì£¼ì¼",
                max_total_results=5,
                collect_details=True
            )

            # ì¢…í•© ê²€ì¦
            assert result.total_found >= 1
            assert result.detailed_issues_count >= 1
            assert result.confidence_score > 0.7
            assert result.average_detail_confidence >= 0.75

            # ì²« ë²ˆì§¸ ì´ìŠˆ ìƒì„¸ ê²€ì¦
            if result.issues and result.issues[0].detailed_content:
                issue = result.issues[0]

                # ê¸°ë³¸ ì •ë³´
                assert issue.title == "OpenAI GPT-4 ì—…ë°ì´íŠ¸"
                assert issue.detailed_content is not None

                # ì—”í‹°í‹° ì •ë³´
                assert len(issue.related_entities) >= 1
                assert issue.related_entities[0].name == "Sam Altman"
                assert issue.related_entities[0].entity_type == "person"

                # ì˜í–¥ë„ ë¶„ì„
                assert issue.impact_analysis is not None
                assert issue.impact_analysis.impact_level == "high"
                assert issue.impact_analysis.impact_score == 0.9
                assert "ê¸°ìˆ " in issue.impact_analysis.affected_sectors

                # íƒ€ì„ë¼ì¸
                assert len(issue.timeline_events) >= 2
                timeline_dates = [event.date for event in issue.timeline_events]
                assert "2024-01-10" in timeline_dates
                assert "2024-01-15" in timeline_dates

                # ë°°ê²½ ì •ë³´
                assert issue.background_context is not None
                assert "OpenAIëŠ” ì§€ì†ì ìœ¼ë¡œ" in issue.background_context

                # ë©”íƒ€ ì •ë³´
                assert issue.detail_confidence > 0.8
                assert issue.detail_collection_time > 0

            # ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸
            from src.issue_searcher import create_detailed_report_from_search_result
            detailed_report = create_detailed_report_from_search_result(result)

            assert "ì¢…í•© ì´ìŠˆ ë¶„ì„ ë³´ê³ ì„œ" in detailed_report
            assert "OpenAI GPT-4 ì—…ë°ì´íŠ¸" in detailed_report
            assert "Sam Altman" in detailed_report


# ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ë“¤ (PerplexityClient, IssueItem, SearchResult ë“±)
class TestPerplexityClient:
    """Perplexity API í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.mark.unit
    def test_perplexity_client_import(self):
        """Perplexity í´ë¼ì´ì–¸íŠ¸ import í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import PerplexityClient, IssueItem, SearchResult
        assert PerplexityClient is not None
        assert IssueItem is not None
        assert SearchResult is not None

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_perplexity_key'})
    def test_perplexity_client_initialization(self):
        """Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import PerplexityClient

        client = PerplexityClient(api_key="test_key")
        assert client.api_key == "test_key"
        assert client.model == "llama-3.1-sonar-large-128k-online"
        assert client.base_url == "https://api.perplexity.ai/chat/completions"
        assert "Authorization" in client.headers
        assert "Bearer test_key" in client.headers["Authorization"]

    @pytest.mark.unit
    def test_perplexity_client_no_api_key(self):
        """API í‚¤ ì—†ì„ ë•Œ ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        with patch.dict(os.environ, {}, clear=True):
            with patch('src.issue_searcher.config') as mock_config:
                mock_config.get_perplexity_api_key.return_value = None

                from src.issue_searcher import PerplexityClient

                with pytest.raises(ValueError, match="Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"):
                    PerplexityClient()


class TestIssueItem:
    """IssueItem ë°ì´í„°í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    def test_issue_item_creation(self):
        """IssueItem ìƒì„± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueItem

        issue = IssueItem(
            title="í…ŒìŠ¤íŠ¸ ì´ìŠˆ",
            summary="í…ŒìŠ¤íŠ¸ ìš”ì•½",
            source="í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤",
            published_date="2024-01-15",
            relevance_score=0.85,
            category="news",
            content_snippet="í…ŒìŠ¤íŠ¸ ë‚´ìš©",
            related_entities=[],
            timeline_events=[]
        )

        assert issue.title == "í…ŒìŠ¤íŠ¸ ì´ìŠˆ"
        assert issue.summary == "í…ŒìŠ¤íŠ¸ ìš”ì•½"
        assert issue.source == "í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤"
        assert issue.published_date == "2024-01-15"
        assert issue.relevance_score == 0.85
        assert issue.category == "news"
        assert issue.content_snippet == "í…ŒìŠ¤íŠ¸ ë‚´ìš©"


class TestSearchResult:
    """SearchResult ë°ì´í„°í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    def test_search_result_creation(self):
        """SearchResult ìƒì„± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import SearchResult, IssueItem

        issue = IssueItem(
            title="í…ŒìŠ¤íŠ¸", summary="í…ŒìŠ¤íŠ¸", source="í…ŒìŠ¤íŠ¸",
            published_date=None, relevance_score=0.5,
            category="news", content_snippet="í…ŒìŠ¤íŠ¸",
            related_entities=[], timeline_events=[]
        )

        result = SearchResult(
            query_keywords=["AI", "ê¸°ìˆ "],
            total_found=1,
            issues=[issue],
            search_time=2.5,
            api_calls_used=1,
            confidence_score=0.8,
            time_period="ìµœê·¼ 1ì£¼ì¼",
            raw_responses=["test response"]
        )

        assert result.query_keywords == ["AI", "ê¸°ìˆ "]
        assert result.total_found == 1
        assert len(result.issues) == 1
        assert result.search_time == 2.5
        assert result.api_calls_used == 1
        assert result.confidence_score == 0.8
        assert result.time_period == "ìµœê·¼ 1ì£¼ì¼"


class TestIssueSearcher:
    """IssueSearcher í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_perplexity_key'})
    def test_issue_searcher_initialization(self):
        """IssueSearcher ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        searcher = IssueSearcher(api_key="test_key")
        assert searcher.client.api_key == "test_key"
        assert searcher.max_keywords_per_search == 5
        assert searcher.max_results_per_search == 10

    @pytest.mark.unit
    def test_prepare_search_keywords(self):
        """ê²€ìƒ‰ í‚¤ì›Œë“œ ì¤€ë¹„ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher
        from src.keyword_generator import KeywordResult

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            keyword_result = KeywordResult(
                topic="AI ê¸°ìˆ ",
                primary_keywords=["AI", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹"],
                related_terms=["ì‹ ê²½ë§", "ì•Œê³ ë¦¬ì¦˜", "ë¹…ë°ì´í„°"],
                synonyms=["Artificial Intelligence"],
                context_keywords=["ê¸°ìˆ í˜ì‹ "],
                confidence_score=0.8,
                generation_time=1.0,
                raw_response="test"
            )

            keywords = searcher._prepare_search_keywords(keyword_result)

            # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ, í•µì‹¬ í‚¤ì›Œë“œ ìš°ì„ 
            assert len(keywords) <= 5
            assert "AI" in keywords
            assert "ì¸ê³µì§€ëŠ¥" in keywords
            assert "ë¨¸ì‹ ëŸ¬ë‹" in keywords

    @pytest.mark.unit
    def test_parse_issue_section(self):
        """ì´ìŠˆ ì„¹ì…˜ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import IssueSearcher

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            section = """AI ê¸°ìˆ  í˜ì‹  ê°€ì†í™”
**ìš”ì•½**: ìµœê·¼ AI ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: Tech News
**ì¼ì**: 2024-01-15
**ì¹´í…Œê³ ë¦¬**: news"""

            issue = searcher._parse_issue_section(section, 1)

            assert issue is not None
            assert issue.title == "AI ê¸°ìˆ  í˜ì‹  ê°€ì†í™”"
            assert "AI ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „" in issue.summary
            assert issue.source == "Tech News"
            assert issue.published_date == "2024-01-15"
            assert issue.category == "news"

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_search_issues_from_keywords_success(self):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì´ìŠˆ ê²€ìƒ‰ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        # Mock API ì‘ë‹µ
        mock_api_response = {
            "choices": [{
                "message": {
                    "content": """**ì œëª©**: AI ê¸°ìˆ  ë°œì „
**ìš”ì•½**: ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: Tech News
**ì¼ì**: 2024-01-15
**ì¹´í…Œê³ ë¦¬**: news

**ì œëª©**: ë¨¸ì‹ ëŸ¬ë‹ í˜ì‹ 
**ìš”ì•½**: ìƒˆë¡œìš´ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.
**ì¶œì²˜**: AI Journal
**ì¼ì**: 2024-01-14
**ì¹´í…Œê³ ë¦¬**: academic"""
                }
            }]
        }

        with patch('src.issue_searcher.PerplexityClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.search_issues.return_value = mock_api_response
            mock_client_class.return_value = mock_client

            from src.issue_searcher import IssueSearcher
            from src.keyword_generator import KeywordResult

            keyword_result = KeywordResult(
                topic="AI ê¸°ìˆ ",
                primary_keywords=["AI", "ì¸ê³µì§€ëŠ¥"],
                related_terms=["ë¨¸ì‹ ëŸ¬ë‹"],
                synonyms=["ê¸°ê³„í•™ìŠµ"],
                context_keywords=["ê¸°ìˆ í˜ì‹ "],
                confidence_score=0.8,
                generation_time=1.0,
                raw_response="test"
            )

            searcher = IssueSearcher(api_key="test_key")
            result = await searcher.search_issues_from_keywords(keyword_result, collect_details=False)

            assert result.total_found == 2
            assert len(result.issues) == 2
            assert result.confidence_score > 0.0
            assert result.search_time > 0.0
            assert "AI" in result.query_keywords

            # ì²« ë²ˆì§¸ ì´ìŠˆ í™•ì¸
            first_issue = result.issues[0]
            assert first_issue.title == "AI ê¸°ìˆ  ë°œì „"
            assert "ì¸ê³µì§€ëŠ¥" in first_issue.summary
            assert first_issue.source == "Tech News"

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_search_issues_from_keywords_failure(self):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì´ìŠˆ ê²€ìƒ‰ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
        with patch('src.issue_searcher.PerplexityClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.search_issues.side_effect = Exception("API ì˜¤ë¥˜")
            mock_client_class.return_value = mock_client

            from src.issue_searcher import IssueSearcher
            from src.keyword_generator import KeywordResult

            keyword_result = KeywordResult(
                topic="í…ŒìŠ¤íŠ¸",
                primary_keywords=["í…ŒìŠ¤íŠ¸"],
                related_terms=[],
                synonyms=[],
                context_keywords=[],
                confidence_score=0.8,
                generation_time=1.0,
                raw_response="test"
            )

            searcher = IssueSearcher(api_key="test_key")
            result = await searcher.search_issues_from_keywords(keyword_result)

            # í´ë°± ê²°ê³¼ í™•ì¸
            assert result.total_found == 0
            assert len(result.issues) == 0
            assert result.confidence_score == 0.1
            assert result.raw_responses == ["ê²€ìƒ‰ ì‹¤íŒ¨ë¡œ ì¸í•œ ì‘ë‹µ ì—†ìŒ"]

    @pytest.mark.unit
    def test_format_search_summary_success(self):
        """ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸ (ì„±ê³µ)"""
        from src.issue_searcher import IssueSearcher, SearchResult, IssueItem

        with patch('src.issue_searcher.PerplexityClient'):
            searcher = IssueSearcher(api_key="test_key")

            issues = [
                IssueItem(
                    title="AI ê¸°ìˆ  ë°œì „",
                    summary="ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    source="Tech News",
                    published_date="2024-01-15",
                    relevance_score=0.9,
                    category="news",
                    content_snippet="test",
                    related_entities=[],
                    timeline_events=[]
                )
            ]

            result = SearchResult(
                query_keywords=["AI", "ê¸°ìˆ "],
                total_found=1,
                issues=issues,
                search_time=2.5,
                api_calls_used=1,
                confidence_score=0.85,
                time_period="ìµœê·¼ 1ì£¼ì¼",
                raw_responses=["test"]
            )

            summary = searcher.format_search_summary(result)

            assert "ì´ìŠˆ ê²€ìƒ‰ ì™„ë£Œ" in summary
            assert "1ê°œ ì´ìŠˆ ë°œê²¬" in summary
            assert "85%" in summary
            assert "AI ê¸°ìˆ  ë°œì „" in summary


class TestConvenienceFunctions:
    """í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.unit
    @patch.dict(os.environ, {'PERPLEXITY_API_KEY': 'test_key'})
    def test_create_issue_searcher(self):
        """create_issue_searcher í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        from src.issue_searcher import create_issue_searcher

        searcher = create_issue_searcher(api_key="test_key")
        assert searcher is not None
        assert searcher.client.api_key == "test_key"


if __name__ == "__main__":
    # pytest ì‹¤í–‰
    pytest.main([__file__, "-v"])