"""
RePPL ê¸°ë°˜ í™˜ê° íƒì§€ ëª¨ë“ˆ (GPT-4o API ê¸°ë°˜ Perplexity ê³„ì‚°)
Repetition as Pre-Perplexityë¥¼ í™œìš©í•œ LLM ì‘ë‹µ ì‹ ë¢°ë„ ê²€ì¦
"""
import re
import numpy as np
import math
import asyncio
from typing import List, Dict, Tuple, Optional
from collections import Counter
from dataclasses import dataclass
from loguru import logger
from sentence_transformers import SentenceTransformer
from openai import AsyncOpenAI
from sklearn.metrics.pairwise import cosine_similarity

from src.config import config
from src.models import KeywordResult, IssueItem, SearchResult
from src.issue_searcher import create_issue_searcher
from src.keyword_generator import generate_keywords_for_topic


@dataclass
class RePPLScore:
    """RePPL ë¶„ì„ ê²°ê³¼"""
    repetition_score: float
    perplexity: float
    semantic_entropy: float
    confidence: float
    repeated_phrases: List[str]
    analysis_details: Dict[str, any]


class RePPLHallucinationDetector:
    """RePPL ê¸°ë°˜ í™˜ê° íƒì§€ê¸° (GPT-4o API ì‚¬ìš©)"""

    def __init__(self, model_name: Optional[str] = None):
        self.api_key = config.get_openai_api_key()
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.perplexity_model = model_name or "gpt-4o"

        self.sentence_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

        self.repetition_threshold = 0.3
        self.perplexity_threshold = 50

        logger.info(f"RePPL í™˜ê° íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ (Perplexity ëª¨ë¸: {self.perplexity_model})")

    async def analyze_response(self, text: str, context: Optional[str] = None) -> RePPLScore:
        logger.debug(f"RePPL ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)})")

        repetition_score, repeated_phrases = self._analyze_repetition(text)
        perplexity = await self._calculate_perplexity_with_gpt(text, context)
        semantic_entropy = self._calculate_semantic_entropy(text)

        confidence = self._calculate_confidence_score(
            repetition_score, perplexity, semantic_entropy
        )

        logger.debug(f"RePPL ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: Repetition={repetition_score:.2f}, PPL={perplexity:.2f}, Entropy={semantic_entropy:.2f} -> Confidence={confidence:.2f}")

        analysis_details = {
            "token_count": len(text.split()),
            "sentence_count": len(text.split('.')),
            "has_context": context is not None
        }

        return RePPLScore(
            repetition_score=repetition_score,
            perplexity=perplexity,
            semantic_entropy=semantic_entropy,
            confidence=confidence,
            repeated_phrases=repeated_phrases,
            analysis_details=analysis_details
        )

    def _analyze_repetition(self, text: str) -> Tuple[float, List[str]]:
        """í…ìŠ¤íŠ¸ ë‚´ ë°˜ë³µ íŒ¨í„´ ë¶„ì„ (êµ¬ë‘ì  ì œê±° ë¡œì§ ì¶”ê°€)"""
        phrases, repeated_phrases_set = [], set()

        # ğŸ’¡ [ìˆ˜ì •] êµ¬ë‘ì ì„ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë‹¨ì–´ ì¼ì¹˜ìœ¨ì„ ë†’ì…ë‹ˆë‹¤.
        cleaned_text = re.sub(r'[^\w\s]', '', text.lower())
        words = cleaned_text.split()

        if not words: return 0.0, []

        for n in range(3, 8):
            if len(words) < n: break
            ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]
            phrase_counts = Counter(ngrams)
            for phrase, count in phrase_counts.items():
                if count > 1:
                    repeated_phrases_set.add(' '.join(phrase))
                    phrases.append((' '.join(phrase), count))

        repeated_words = sum(len(p.split()) * (c - 1) for p, c in phrases)
        repetition_score = min(1.0, repeated_words / len(words)) if len(words) > 0 else 0.0

        logger.debug(f"ë°˜ë³µì„± ì ìˆ˜: {repetition_score:.3f}, ë°˜ë³µëœ êµ¬ë¬¸: {len(repeated_phrases_set)}ê°œ")
        return repetition_score, list(repeated_phrases_set)

    async def _calculate_perplexity_with_gpt(self, text: str, context: Optional[str] = None) -> float:
        if not text.strip(): return self.perplexity_threshold * 2
        logger.debug(f"Perplexity ê³„ì‚° ìš”ì²­ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)})")
        try:
            full_text = f"Context: {context}\n\nText to evaluate: {text}" if context else text
            response = await self.client.chat.completions.create(model=self.perplexity_model, messages=[{"role": "user", "content": full_text}], max_tokens=2048, temperature=0, logprobs=True)
            logprobs = [token.logprob for token in response.choices[0].logprobs.content if token.logprob is not None]
            if not logprobs: return self.perplexity_threshold * 2
            mean_logprob = sum(logprobs) / len(logprobs)
            perplexity = math.exp(-mean_logprob)
            logger.debug(f"GPT Perplexity ê³„ì‚° ì„±ê³µ: {perplexity:.2f}")
            return perplexity
        except Exception as e:
            logger.error(f"GPT Perplexity ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self.perplexity_threshold * 2

    def _calculate_semantic_entropy(self, text: str) -> float:
        """ë¬¸ì¥ ê°„ ì˜ë¯¸ì  ë‹¤ì–‘ì„±(ì—”íŠ¸ë¡œí”¼) ê³„ì‚° (ì•ˆì •ì„± ê°•í™”)"""
        sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 5]
        if len(sentences) < 2:
            return 0.0
        embeddings = self.sentence_model.encode(sentences)
        sim_matrix = cosine_similarity(embeddings)
        num_sentences = len(sentences)
        np.fill_diagonal(sim_matrix, 0)
        avg_similarity = np.sum(sim_matrix) / (num_sentences * (num_sentences - 1))
        entropy = 1 - avg_similarity
        logger.debug(f"ì˜ë¯¸ì  ì—”íŠ¸ë¡œí”¼ ê³„ì‚°ë¨: {entropy:.3f} (ë¬¸ì¥ {len(sentences)}ê°œ ê¸°ë°˜)")
        return entropy

    def _calculate_confidence_score(self, repetition: float, perplexity: float, entropy: float) -> float:
        rep_score = 1 - min(1.0, repetition / self.repetition_threshold)
        ppl_score = max(0.0, 1 - (perplexity / self.perplexity_threshold))
        ent_score = min(1.0, entropy)
        weights = {'repetition': 0.4, 'perplexity': 0.3, 'entropy': 0.3}
        confidence = (weights['repetition'] * rep_score + weights['perplexity'] * ppl_score + weights['entropy'] * ent_score)
        return round(confidence, 3)


class RePPLEnhancedIssueSearcher:
    """RePPLì´ í†µí•©ëœ ì´ìŠˆ ê²€ìƒ‰ê¸°"""
    def __init__(self, api_key: Optional[str] = None):
        self.base_searcher = create_issue_searcher(api_key)
        self.reppl_detector = RePPLHallucinationDetector()
        self.min_confidence_threshold = 0.5
        logger.info("RePPL ê°•í™” ì´ìŠˆ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    async def search_with_validation(self, keyword_result: KeywordResult, time_period: str) -> SearchResult:
        max_retries = 2
        current_keywords = keyword_result
        for attempt in range(max_retries):
            search_result = await self.base_searcher.search_issues_from_keywords(current_keywords, time_period, collect_details=True)
            validated_issues = []
            if search_result.issues:
                validation_tasks = [self._validate_issue(issue, current_keywords.topic) for issue in search_result.issues]
                validation_results = await asyncio.gather(*validation_tasks)
                validated_issues = [issue for issue in validation_results if issue is not None]
            if len(validated_issues) >= 3 or attempt == max_retries - 1:
                search_result.issues = validated_issues
                search_result.total_found = len(validated_issues)
                return search_result
            logger.info(f"ì‹ ë¢°ë„ ë†’ì€ ì´ìŠˆ ë¶€ì¡±, í‚¤ì›Œë“œë¥¼ ì¬ìƒì„±í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            current_keywords = await generate_keywords_for_topic(f"{current_keywords.topic}ì˜ ë‹¤ë¥¸ ê´€ì ")
        return search_result

    async def _validate_issue(self, issue: IssueItem, topic: str) -> Optional[IssueItem]:
        content_to_validate = f"ì œëª©: {issue.title}\nìš”ì•½: {issue.summary}"
        if issue.detailed_content:
            content_to_validate += f"\nìƒì„¸ë‚´ìš©: {issue.detailed_content[:500]}"
        reppl_score = await self.reppl_detector.analyze_response(content_to_validate, context=topic)
        if reppl_score.confidence >= self.min_confidence_threshold:
            setattr(issue, 'reppl_confidence', reppl_score.confidence)
            setattr(issue, 'reppl_analysis', reppl_score)
            logger.debug(f"ì´ìŠˆ '{issue.title[:30]}...' ê²€ì¦ í†µê³¼ (ì‹ ë¢°ë„: {reppl_score.confidence:.2f})")
            return issue
        else:
            logger.warning(f"ì´ìŠˆ '{issue.title[:30]}...' ì œì™¸ë¨ - RePPL ì‹ ë¢°ë„: {reppl_score.confidence:.2f}")
            return None