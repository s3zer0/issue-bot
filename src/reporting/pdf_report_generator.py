"""
PDF ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ.

ì´ìŠˆ ë¶„ì„ ê²°ê³¼ë¥¼ LLMìœ¼ë¡œ ê°œì„ í•˜ê³  ê¹”ë”í•œ PDF í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ë””ìì¸ì˜ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
from datetime import datetime
from typing import List, Optional, Dict, Any
from io import BytesIO
import asyncio

from reportlab.lib import colors
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch, cm
from reportlab.platypus import (
    SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer,
    PageBreak, Image, KeepTogether, ListFlowable, ListItem
)
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY, TA_RIGHT
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.utils import ImageReader
from loguru import logger
import openai

from src.models import SearchResult, IssueItem
from src.config import config
from src.hallucination_detection.threshold_manager import ThresholdManager
from src.reporting.markdown_parser import MarkdownToPDFConverter
from src.reporting.topic_classifier import TopicClassifier


class PDFReportGenerator:
    """LLMì„ í™œìš©í•œ PDF ë³´ê³ ì„œ ìƒì„±ê¸°."""

    def __init__(self, openai_api_key: Optional[str] = None):
        """
        PDF ë³´ê³ ì„œ ìƒì„±ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            openai_api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        """
        self.api_key = openai_api_key or config.get_openai_api_key()
        self.threshold_manager = ThresholdManager()

        # í•œê¸€ í°íŠ¸ ì„¤ì • (NanumGothic ë˜ëŠ” ì‹œìŠ¤í…œ í°íŠ¸ ì‚¬ìš©)
        self._setup_fonts()

        # Performance: Initialize markdown converter for better text formatting
        self.markdown_converter = MarkdownToPDFConverter(self.default_font)
        
        # Dynamic: Initialize topic classifier for adaptive sections
        self.topic_classifier = TopicClassifier()

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        self.styles = getSampleStyleSheet()
        self._setup_custom_styles()

        logger.info("PDF ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def _setup_fonts(self):
        """í•œê¸€ ì§€ì›ì„ ìœ„í•œ í°íŠ¸ ì„¤ì • - NotoSansKR ì‚¬ìš©."""
        try:
            # Use absolute path to Fonts directory
            font_path = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
                "Fonts",
                "NotoSansKR-VariableFont_wght.ttf"
            )
            
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('NotoSansKR', font_path))
                self.default_font = 'NotoSansKR'
                logger.info(f"Successfully registered NotoSansKR font from: {font_path}")
            else:
                # Fallback for different OS
                if os.name == 'nt':
                    # Windows
                    malgun = "C:/Windows/Fonts/malgun.ttf"
                    if os.path.exists(malgun):
                        pdfmetrics.registerFont(TTFont('MalgunGothic', malgun))
                        self.default_font = 'MalgunGothic'
                        logger.info("Using MalgunGothic font on Windows")
                    else:
                        self.default_font = 'Helvetica'
                        logger.warning("Korean font not found on Windows, using Helvetica")
                else:
                    # macOS/Linux
                    nanum = "/Library/Fonts/NanumGothic.ttf"
                    if os.path.exists(nanum):
                        pdfmetrics.registerFont(TTFont('NanumGothic', nanum))
                        self.default_font = 'NanumGothic'
                        logger.info("Using NanumGothic font")
                    else:
                        # Last resort - use Helvetica (no Korean support)
                        self.default_font = 'Helvetica'
                        logger.warning("Korean font not found, using Helvetica (Korean text may not display properly)")
                        
        except Exception as e:
            logger.error(f"Font registration error: {e}")
            self.default_font = 'Helvetica'
    
    def _format_text_for_font(self, text: str) -> str:
        """í°íŠ¸ í˜¸í™˜ì„±ì— ë”°ë¼ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì¡°ì •."""
        # NotoSansKR and other TTF fonts support bold/italic, so no need to strip tags
        # Only strip tags if using Helvetica as fallback
        if self.default_font == 'Helvetica':
            # Helvetica doesn't support Korean, so we might want to warn about this
            if any('\u3131' <= char <= '\u318e' or '\uac00' <= char <= '\ud7a3' for char in text):
                logger.warning("Korean text detected but Korean font not available")
        return text

    def _setup_custom_styles(self):
        """ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì •ì˜."""
        # ì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='CustomTitle',
            parent=self.styles['Title'],
            fontName=self.default_font,
            fontSize=24,
            textColor=colors.HexColor('#1a1a1a'),
            spaceAfter=30,
            alignment=TA_CENTER
        ))

        # ë¶€ì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='CustomHeading1',
            parent=self.styles['Heading1'],
            fontName=self.default_font,
            fontSize=18,
            textColor=colors.HexColor('#2c3e50'),
            spaceBefore=20,
            spaceAfter=15,
            borderColor=colors.HexColor('#3498db'),
            borderWidth=2,
            borderPadding=5,
            borderRadius=3
        ))

        # ì†Œì œëª© ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='CustomHeading2',
            parent=self.styles['Heading2'],
            fontName=self.default_font,
            fontSize=14,
            textColor=colors.HexColor('#34495e'),
            spaceBefore=15,
            spaceAfter=10
        ))

        # ë³¸ë¬¸ ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='CustomBody',
            parent=self.styles['BodyText'],
            fontName=self.default_font,
            fontSize=11,
            leading=16,
            alignment=TA_JUSTIFY,
            textColor=colors.HexColor('#2c3e50')
        ))

        # ê°•ì¡° ìŠ¤íƒ€ì¼
        self.styles.add(ParagraphStyle(
            name='CustomEmphasis',
            parent=self.styles['BodyText'],
            fontName=self.default_font,
            fontSize=11,
            leading=16,
            textColor=colors.HexColor('#e74c3c'),
            alignment=TA_LEFT
        ))

    async def enhance_content_with_llm(self, search_result: SearchResult) -> Dict[str, Any]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë³´ê³ ì„œ ë‚´ìš©ì„ ê°œì„ í•˜ê³  êµ¬ì¡°í™”í•©ë‹ˆë‹¤.

        Args:
            search_result: ê²€ìƒ‰ ê²°ê³¼ ê°ì²´

        Returns:
            Dict: LLMì´ ê°œì„ í•œ ë³´ê³ ì„œ êµ¬ì¡°
        """
        if not self.api_key:
            logger.warning("OpenAI API í‚¤ê°€ ì—†ì–´ LLM ê°œì„ ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return self._create_basic_structure(search_result)

        try:
            client = openai.AsyncOpenAI(api_key=self.api_key)

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸°ìˆ  ë³´ê³ ì„œ ì‘ì„±ìì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ìŠˆ ëª¨ë‹ˆí„°ë§ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 
ê²½ì˜ì§„ì„ ìœ„í•œ ê¹”ë”í•˜ê³  ì¸ì‚¬ì´íŠ¸ ìˆëŠ” ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì£¼ì œ: {', '.join(search_result.query_keywords)}
ê¸°ê°„: {search_result.time_period}
ë°œê²¬ëœ ì´ìŠˆ ìˆ˜: {search_result.total_found}

ì£¼ìš” ì´ìŠˆë“¤:
"""
            # ìƒìœ„ 5ê°œ ì´ìŠˆ ìš”ì•½
            for i, issue in enumerate(search_result.issues[:5], 1):
                prompt += f"\n{i}. {issue.title}\n   - {issue.summary}\n   - ì‹ ë¢°ë„: {getattr(issue, 'combined_confidence', 0.5):.1%}\n"

            prompt += """
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. í•µì‹¬ ìš”ì•½ (Executive Summary): 3-4ë¬¸ì¥ìœ¼ë¡œ ì „ì²´ ìƒí™©ì„ ìš”ì•½
2. ì£¼ìš” ë°œê²¬ì‚¬í•­ (Key Findings): ê°€ì¥ ì¤‘ìš”í•œ 3-5ê°œ ì¸ì‚¬ì´íŠ¸ë¥¼ bullet pointë¡œ
3. íŠ¸ë Œë“œ ë¶„ì„ (Trend Analysis): ë°œê²¬ëœ ì´ìŠˆë“¤ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œ
4. ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ (Risks & Opportunities): ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒ
5. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ (Recommended Actions): êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ 3-5ê°œ

ê° ì„¹ì…˜ì€ ê°„ê²°í•˜ë©´ì„œë„ ì¸ì‚¬ì´íŠ¸ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. 
ì „ë¬¸ ìš©ì–´ëŠ” í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""

            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )

            # LLM ì‘ë‹µ íŒŒì‹±
            enhanced_content = self._parse_llm_response(
                response.choices[0].message.content,
                search_result
            )

            logger.info("LLMì„ í†µí•œ ë³´ê³ ì„œ ë‚´ìš© ê°œì„  ì™„ë£Œ")
            return enhanced_content

        except Exception as e:
            logger.error(f"LLM ê°œì„  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._create_basic_structure(search_result)

    def _parse_llm_response(self, llm_response: str, search_result: SearchResult) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜."""
        sections = {
            'executive_summary': '',
            'key_findings': [],
            'trend_analysis': '',
            'risks_opportunities': '',
            'recommended_actions': []
        }

        current_section = None
        current_content = []
        lines = llm_response.strip().split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # ì„¹ì…˜ í—¤ë” ê°ì§€ (ë” ìœ ì—°í•œ ë§¤ì¹­)
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in ['í•µì‹¬ ìš”ì•½', 'executive summary']):
                if current_section and current_content:
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    self._save_section_content(sections, current_section, current_content)
                current_section = 'executive_summary'
                current_content = []
                continue
            elif any(keyword in line_lower for keyword in ['ì£¼ìš” ë°œê²¬', 'key findings']):
                if current_section and current_content:
                    self._save_section_content(sections, current_section, current_content)
                current_section = 'key_findings'
                current_content = []
                continue
            elif any(keyword in line_lower for keyword in ['íŠ¸ë Œë“œ ë¶„ì„', 'trend analysis']):
                if current_section and current_content:
                    self._save_section_content(sections, current_section, current_content)
                current_section = 'trend_analysis'
                current_content = []
                continue
            elif any(keyword in line_lower for keyword in ['ë¦¬ìŠ¤í¬', 'risks', 'ê¸°íšŒ', 'opportunities']):
                if current_section and current_content:
                    self._save_section_content(sections, current_section, current_content)
                current_section = 'risks_opportunities'
                current_content = []
                continue
            elif any(keyword in line_lower for keyword in ['ê¶Œì¥ ì¡°ì¹˜', 'recommended actions']):
                if current_section and current_content:
                    self._save_section_content(sections, current_section, current_content)
                current_section = 'recommended_actions'
                current_content = []
                continue

            # ë‚´ìš© ì¶”ê°€
            if current_section:
                current_content.append(line)

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section and current_content:
            self._save_section_content(sections, current_section, current_content)

        # ê¸°ë³¸ êµ¬ì¡°ì™€ ë³‘í•©
        return {
            'search_result': search_result,
            'enhanced_sections': sections,
            'metadata': {
                'generated_at': datetime.now(),
                'llm_enhanced': True
            }
        }

    def _save_section_content(self, sections: Dict, section_name: str, content_lines: List[str]):
        """ì„¹ì…˜ ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ."""
        if section_name in ['key_findings', 'recommended_actions']:
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
            for line in content_lines:
                clean_line = line.lstrip('-â€¢* 0123456789.')
                if clean_line:
                    sections[section_name].append(clean_line)
        else:
            # í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
            sections[section_name] = ' '.join(content_lines)

    def _create_basic_structure(self, search_result: SearchResult) -> Dict[str, Any]:
        """LLM ì—†ì´ ê¸°ë³¸ ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±."""
        # ì‹ ë¢°ë„ë³„ ì´ìŠˆ ë¶„ë¥˜
        high, moderate, low = self.threshold_manager.filter_issues_by_confidence(
            search_result.issues
        )

        # ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±
        key_findings = []
        for issue in high[:3]:  # ìƒìœ„ 3ê°œ ë†’ì€ ì‹ ë¢°ë„ ì´ìŠˆ
            key_findings.append(f"{issue.title}: {issue.summary[:100]}...")

        # ë°œê²¬ì‚¬í•­ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ì¶”ê°€
        if not key_findings:
            key_findings = ["ì‹ ë¢°ë„ ë†’ì€ ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]

        return {
            'search_result': search_result,
            'enhanced_sections': {
                'executive_summary': f"{len(search_result.issues)}ê°œì˜ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìœ¼ë©°, "
                                   f"ì´ ì¤‘ {len(high)}ê°œê°€ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.",
                'key_findings': key_findings,
                'trend_analysis': 'ìˆ˜ì§‘ëœ ì´ìŠˆë“¤ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.',
                'risks_opportunities': 'ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                'recommended_actions': ['ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ í•„ìš”', 'ì£¼ìš” ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„ ê¶Œì¥']
            },
            'metadata': {
                'generated_at': datetime.now(),
                'llm_enhanced': False
            }
        }

    def generate_pdf(self, enhanced_data: Dict[str, Any], output_path: str) -> str:
        """
        PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            enhanced_data: LLMìœ¼ë¡œ ê°œì„ ëœ ë³´ê³ ì„œ ë°ì´í„°
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ

        Returns:
            str: ìƒì„±ëœ PDF íŒŒì¼ ê²½ë¡œ
        """
        doc = SimpleDocTemplate(
            output_path,
            pagesize=A4,
            rightMargin=2*cm,
            leftMargin=2*cm,
            topMargin=2*cm,
            bottomMargin=2*cm
        )

        # ë¬¸ì„œ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        story = []

        # í‘œì§€
        story.extend(self._create_cover_page(enhanced_data))
        story.append(PageBreak())

        # ëª©ì°¨
        story.extend(self._create_table_of_contents())
        story.append(PageBreak())

        # í•µì‹¬ ìš”ì•½
        story.extend(self._create_executive_summary(enhanced_data))
        story.append(PageBreak())

        # Dynamic: Generate sections based on topic classification
        story.extend(self._create_dynamic_sections(enhanced_data))

        # ë¶€ë¡
        story.extend(self._create_appendix(enhanced_data))

        # PDF ìƒì„±
        doc.build(story, onFirstPage=self._add_page_number, onLaterPages=self._add_page_number)

        logger.info(f"PDF ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_path}")
        return output_path

    def _create_cover_page(self, data: Dict[str, Any]) -> List:
        """í‘œì§€ í˜ì´ì§€ ìƒì„±."""
        story = []
        search_result = data['search_result']

        # ì—¬ë°±
        story.append(Spacer(1, 3*inch))

        # ì œëª©
        title = Paragraph(
            self._format_text_for_font(f"<b>AI ì´ìŠˆ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ</b>"),
            self.styles['CustomTitle']
        )
        story.append(title)

        story.append(Spacer(1, 0.5*inch))

        # ë¶€ì œëª©
        subtitle = Paragraph(
            self._format_text_for_font(f"<b>{', '.join(search_result.query_keywords[:3])}</b>"),
            ParagraphStyle(
                'Subtitle',
                parent=self.styles['CustomTitle'],
                fontSize=18,
                textColor=colors.HexColor('#7f8c8d')
            )
        )
        story.append(subtitle)

        story.append(Spacer(1, 2*inch))

        # ë©”íƒ€ì •ë³´ í…Œì´ë¸”
        meta_data = [
            ['ìƒì„±ì¼ì‹œ', datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')],
            ['ê²€ìƒ‰ ê¸°ê°„', search_result.time_period],
            ['ë°œê²¬ ì´ìŠˆ', f'{search_result.total_found}ê°œ'],
            ['ì‹ ë¢°ë„ í‰ê°€', 'AI í™˜ê° íƒì§€ ì‹œìŠ¤í…œ ì ìš©']
        ]

        meta_table = Table(meta_data, colWidths=[3*inch, 3*inch])
        meta_table.setStyle(TableStyle([
            ('FONTNAME', (0, 0), (-1, -1), self.default_font),
            ('FONTSIZE', (0, 0), (-1, -1), 11),
            ('TEXTCOLOR', (0, 0), (0, -1), colors.HexColor('#7f8c8d')),
            ('TEXTCOLOR', (1, 0), (1, -1), colors.HexColor('#2c3e50')),
            ('ALIGN', (0, 0), (0, -1), 'RIGHT'),
            ('ALIGN', (1, 0), (1, -1), 'LEFT'),
            ('LINEBELOW', (0, 0), (-1, -2), 0.5, colors.HexColor('#ecf0f1')),
            ('TOPPADDING', (0, 0), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ]))

        story.append(meta_table)

        return story

    def _create_table_of_contents(self) -> List:
        """ëª©ì°¨ ìƒì„±."""
        story = []

        story.append(Paragraph("ëª©ì°¨", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.3*inch))

        toc_items = [
            ("1. í•µì‹¬ ìš”ì•½", "3"),
            ("2. ì£¼ìš” ë°œê²¬ì‚¬í•­", "4"),
            ("3. ìƒì„¸ ì´ìŠˆ ë¶„ì„", "5"),
            ("4. íŠ¸ë Œë“œ ë¶„ì„", "8"),
            ("5. ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ", "9"),
            ("6. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­", "10"),
            ("ë¶€ë¡. í™˜ê° íƒì§€ ìƒì„¸ ê²°ê³¼", "11")
        ]

        for item, page in toc_items:
            # ë§í¬ ì—†ì´ ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œ ìƒì„±
            toc_line = Paragraph(
                f'{item}{"." * (50 - len(item))}{page}',
                ParagraphStyle(
                    'TOCItem',
                    parent=self.styles['CustomBody'],
                    leftIndent=20,
                    rightIndent=20
                )
            )
            story.append(toc_line)
            story.append(Spacer(1, 0.1*inch))

        return story

    def _create_executive_summary(self, data: Dict[str, Any]) -> List:
        """í•µì‹¬ ìš”ì•½ ì„¹ì…˜ ìƒì„±."""
        story = []
        sections = data['enhanced_sections']

        story.append(Paragraph("1. í•µì‹¬ ìš”ì•½", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.2*inch))

        summary_text = sections.get('executive_summary', 'ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
        story.append(Paragraph(summary_text, self.styles['CustomBody']))

        story.append(Spacer(1, 0.3*inch))

        # í•µì‹¬ ì§€í‘œ í…Œì´ë¸”
        search_result = data['search_result']
        high, moderate, low = self.threshold_manager.filter_issues_by_confidence(
            search_result.issues
        )

        metrics_data = [
            ['êµ¬ë¶„', 'ìˆ˜ì¹˜', 'ë¹„ìœ¨'],
            ['ì „ì²´ ì´ìŠˆ', f'{search_result.total_found}ê°œ', '100%'],
            ['ë†’ì€ ì‹ ë¢°ë„', f'{len(high)}ê°œ', f'{len(high)/max(1, search_result.total_found)*100:.1f}%'],
            ['ì¤‘ê°„ ì‹ ë¢°ë„', f'{len(moderate)}ê°œ', f'{len(moderate)/max(1, search_result.total_found)*100:.1f}%'],
            ['ë‚®ì€ ì‹ ë¢°ë„', f'{len(low)}ê°œ', f'{len(low)/max(1, search_result.total_found)*100:.1f}%']
        ]

        metrics_table = Table(metrics_data, colWidths=[2*inch, 1.5*inch, 1.5*inch])
        metrics_table.setStyle(TableStyle([
            ('FONTNAME', (0, 0), (-1, -1), self.default_font),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#bdc3c7')),
            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#ecf0f1')]),
        ]))

        story.append(metrics_table)

        return story

    def _create_key_findings(self, data: Dict[str, Any]) -> List:
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ì„¹ì…˜ ìƒì„±."""
        story = []
        sections = data['enhanced_sections']

        story.append(Paragraph("2. ì£¼ìš” ë°œê²¬ì‚¬í•­", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.2*inch))

        findings = sections.get('key_findings', [])
        if findings:
            for i, finding in enumerate(findings, 1):
                bullet = Paragraph(f"â€¢ {finding}", self.styles['CustomBody'])
                story.append(bullet)
                story.append(Spacer(1, 0.1*inch))
        else:
            story.append(Paragraph("ì£¼ìš” ë°œê²¬ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.", self.styles['CustomBody']))

        story.append(Spacer(1, 0.3*inch))
        return story

    def _create_detailed_issues(self, data: Dict[str, Any]) -> List:
        """ìƒì„¸ ì´ìŠˆ ë¶„ì„ ì„¹ì…˜ ìƒì„±."""
        story = []
        search_result = data['search_result']

        story.append(Paragraph("3. ìƒì„¸ ì´ìŠˆ ë¶„ì„", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.2*inch))

        # ì‹ ë¢°ë„ë³„ë¡œ ì´ìŠˆ ë¶„ë¥˜
        high, moderate, low = self.threshold_manager.filter_issues_by_confidence(
            search_result.issues
        )

        # ë†’ì€ ì‹ ë¢°ë„ ì´ìŠˆ
        if high:
            story.append(Paragraph("ë†’ì€ ì‹ ë¢°ë„ ì´ìŠˆ", self.styles['CustomHeading2']))
            for issue in high[:5]:  # ìƒìœ„ 5ê°œë§Œ
                story.extend(self._create_issue_detail(issue))

        # ì¤‘ê°„ ì‹ ë¢°ë„ ì´ìŠˆ
        if moderate and len(story) < 100:  # í˜ì´ì§€ ìˆ˜ ì œí•œ
            story.append(Paragraph("ì¤‘ê°„ ì‹ ë¢°ë„ ì´ìŠˆ", self.styles['CustomHeading2']))
            for issue in moderate[:3]:  # ìƒìœ„ 3ê°œë§Œ
                story.extend(self._create_issue_detail(issue))

        return story

    def _create_issue_detail(self, issue: IssueItem) -> List:
        """ê°œë³„ ì´ìŠˆ ìƒì„¸ ì •ë³´ ìƒì„± (Enhanced with markdown parsing)."""
        story = []

        # Enhanced: Use markdown converter for title formatting
        title_markdown = f"## {issue.title}"
        title_elements = self.markdown_converter.convert_to_pdf_elements(title_markdown)
        story.extend(title_elements)

        # Enhanced: Visual confidence indicator with color coding
        confidence = getattr(issue, 'combined_confidence', 0.5)
        confidence_indicator = self.markdown_converter.format_confidence_text(confidence)
        
        meta_info = f"**ì¶œì²˜**: {issue.source} | **ë°œí–‰ì¼**: {issue.published_date or 'N/A'} | **ì‹ ë¢°ë„**: {confidence_indicator}"
        meta_elements = self.markdown_converter.convert_to_pdf_elements(meta_info)
        story.extend(meta_elements)
        
        story.append(Spacer(1, 0.1*inch))

        # Enhanced: Parse summary as markdown for better formatting
        summary_markdown = f"### ìš”ì•½\n{issue.summary}"
        summary_elements = self.markdown_converter.convert_to_pdf_elements(summary_markdown)
        story.extend(summary_elements)

        # Enhanced: Parse detailed content as markdown (if exists)
        if issue.detailed_content:
            story.append(Spacer(1, 0.1*inch))
            
            # Truncate if too long but preserve markdown structure
            detailed_content = issue.detailed_content
            if len(detailed_content) > 1000:
                # Find a good break point (end of paragraph or sentence)
                truncate_point = 1000
                for punct in ['\n\n', '\n', '. ', '? ', '! ']:
                    last_punct = detailed_content.rfind(punct, 0, 1000)
                    if last_punct > 800:  # Must be reasonably long
                        truncate_point = last_punct + len(punct)
                        break
                detailed_content = detailed_content[:truncate_point] + "\n\n*[ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë©ë‹ˆë‹¤...]*"
            
            detail_markdown = f"### ìƒì„¸ ë‚´ìš©\n{detailed_content}"
            detail_elements = self.markdown_converter.convert_to_pdf_elements(detail_markdown)
            story.extend(detail_elements)

        story.append(Spacer(1, 0.2*inch))
        return story

    def _create_trend_analysis(self, data: Dict[str, Any]) -> List:
        """íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ ìƒì„± (Enhanced with markdown parsing)."""
        story = []
        sections = data['enhanced_sections']

        # Enhanced: Use markdown for section header
        header_markdown = "# 4. íŠ¸ë Œë“œ ë¶„ì„"
        header_elements = self.markdown_converter.convert_to_pdf_elements(header_markdown)
        story.extend(header_elements)

        # Enhanced: Parse trend analysis content as markdown
        trend_text = sections.get('trend_analysis', 'íŠ¸ë Œë“œ ë¶„ì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
        trend_elements = self.markdown_converter.convert_to_pdf_elements(trend_text)
        story.extend(trend_elements)

        story.append(Spacer(1, 0.3*inch))
        return story

    def _create_risks_opportunities(self, data: Dict[str, Any]) -> List:
        """ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ì„¹ì…˜ ìƒì„± (Enhanced with markdown parsing)."""
        story = []
        sections = data['enhanced_sections']

        # Enhanced: Use markdown for section header
        header_markdown = "# 5. ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ"
        header_elements = self.markdown_converter.convert_to_pdf_elements(header_markdown)
        story.extend(header_elements)

        # Enhanced: Parse risks and opportunities content as markdown
        ro_text = sections.get('risks_opportunities', 'ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ë¶„ì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
        ro_elements = self.markdown_converter.convert_to_pdf_elements(ro_text)
        story.extend(ro_elements)

        story.append(Spacer(1, 0.3*inch))
        return story

    def _create_dynamic_sections(self, data: Dict[str, Any]) -> List:
        """
        Dynamic: Generate report sections based on topic classification.
        Only creates relevant sections for the specific topic type.
        """
        story = []
        search_result = data['search_result']
        
        # Classify the topic
        topic = " ".join(search_result.query_keywords)
        keywords = search_result.query_keywords
        classification = self.topic_classifier.classify_topic(topic, keywords)
        
        logger.info(f"Topic classified as: {classification.primary_type.value} "
                   f"(confidence: {classification.confidence:.1%})")
        
        # Add classification info to the report
        classification_markdown = f"""
## ğŸ¯ ì£¼ì œ ë¶„ì„ ê²°ê³¼

**ì£¼ì œ ìœ í˜•**: {self._get_topic_type_korean(classification.primary_type)}  
**ì‹ ë¢°ë„**: {classification.confidence:.1%}  
**ë¶„ì„ ê·¼ê±°**: {classification.reasoning}  
**ë§¤ì¹­ í‚¤ì›Œë“œ**: {', '.join(classification.keywords_matched)}

---
"""
        classification_elements = self.markdown_converter.convert_to_pdf_elements(classification_markdown)
        story.extend(classification_elements)
        
        # Generate sections based on classification
        section_number = 2  # Start after executive summary
        
        # Always include key findings
        story.extend(self._create_key_findings(data))
        section_number += 1
        
        # Always include detailed issues
        story.extend(self._create_detailed_issues(data))
        section_number += 1
        
        # Conditionally include other sections based on topic type
        if self._should_include_trend_analysis(classification):
            story.extend(self._create_trend_analysis(data))
            section_number += 1
        
        if self._should_include_risk_analysis(classification):
            story.extend(self._create_risks_opportunities(data))
            section_number += 1
        
        # Always include recommendations but adapt content
        story.extend(self._create_adaptive_recommendations(data, classification))
        
        return story

    def _get_topic_type_korean(self, topic_type) -> str:
        """Convert topic type to Korean description."""
        type_names = {
            'technical_announcement': 'ê¸°ìˆ  ë°œí‘œ/ì—…ë°ì´íŠ¸',
            'product_launch': 'ì œí’ˆ ì¶œì‹œ',
            'business_strategic': 'ë¹„ì¦ˆë‹ˆìŠ¤/ì „ëµ',
            'research_scientific': 'ì—°êµ¬/ê³¼í•™',
            'social_political': 'ì‚¬íšŒ/ì •ì¹˜',
            'financial_market': 'ê¸ˆìœµ/ì‹œì¥',
            'general': 'ì¼ë°˜'
        }
        return type_names.get(topic_type.value, 'ì¼ë°˜')

    def _should_include_trend_analysis(self, classification) -> bool:
        """Determine if trend analysis should be included."""
        # Include for most types except pure technical announcements
        if classification.primary_type.value == 'technical_announcement' and classification.confidence > 0.8:
            return False
        return True

    def _should_include_risk_analysis(self, classification) -> bool:
        """Determine if risk analysis should be included."""
        return self.topic_classifier.should_include_risk_analysis(classification)

    def _create_adaptive_recommendations(self, data: Dict[str, Any], classification) -> List:
        """Create recommendations adapted to topic type."""
        story = []
        sections = data['enhanced_sections']

        # Adaptive header based on topic type
        if classification.primary_type.value == 'technical_announcement':
            header = "# ğŸ”§ ê¸°ìˆ  êµ¬í˜„ ê°€ì´ë“œë¼ì¸"
        elif classification.primary_type.value == 'product_launch':
            header = "# ğŸ“± ì œí’ˆ í™œìš© ë°©ì•ˆ"
        elif classification.primary_type.value == 'business_strategic':
            header = "# ğŸ“Š ì „ëµì  ëŒ€ì‘ ë°©ì•ˆ"
        elif classification.primary_type.value == 'research_scientific':
            header = "# ğŸ”¬ ì—°êµ¬ í™œìš© ë° í›„ì† ì—°êµ¬"
        else:
            header = "# ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­"

        header_elements = self.markdown_converter.convert_to_pdf_elements(header)
        story.extend(header_elements)

        # Adaptive content
        recommendations = sections.get('recommended_actions', [])
        if recommendations:
            rec_text = "\n".join([f"- {rec}" for rec in recommendations])
        else:
            # Generate default recommendations based on topic type
            rec_text = self._generate_default_recommendations(classification)

        rec_elements = self.markdown_converter.convert_to_pdf_elements(rec_text)
        story.extend(rec_elements)

        story.append(Spacer(1, 0.3*inch))
        return story

    def _generate_default_recommendations(self, classification) -> str:
        """Generate default recommendations based on topic type."""
        if classification.primary_type.value == 'technical_announcement':
            return """
- ìƒˆë¡œìš´ ê¸°ìˆ  ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
- ê°œë°œíŒ€ê³¼ ê¸°ìˆ  ë³€í™” ì‚¬í•­ì„ ê³µìœ í•˜ì„¸ìš”
- í˜¸í™˜ì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
- ê´€ë ¨ ë¬¸ì„œ ë° ê°€ì´ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”
"""
        elif classification.primary_type.value == 'business_strategic':
            return """
- ì‹œì¥ ë³€í™”ì— ë”°ë¥¸ ì „ëµ ì¡°ì •ì„ ê²€í† í•˜ì„¸ìš”
- ê²½ìŸì‚¬ ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”
- ì´í•´ê´€ê³„ìë“¤ê³¼ ì†Œí†µ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì²´ê³„ë¥¼ ê°•í™”í•˜ì„¸ìš”
"""
        else:
            return """
- ê´€ë ¨ ì •ë³´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”
- ì£¼ìš” ì´í•´ê´€ê³„ìë“¤ê³¼ ì •ë³´ë¥¼ ê³µìœ í•˜ì„¸ìš”
- í•„ìš”ì‹œ ì „ë¬¸ê°€ ì˜ê²¬ì„ êµ¬í•˜ì„¸ìš”
- ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
"""

    def _create_recommendations(self, data: Dict[str, Any]) -> List:
        """ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ ì„¹ì…˜ ìƒì„±."""
        story = []
        sections = data['enhanced_sections']

        story.append(Paragraph("6. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.2*inch))

        actions = sections.get('recommended_actions', [])
        if actions:
            for i, action in enumerate(actions, 1):
                bullet = Paragraph(f"{i}. {action}", self.styles['CustomBody'])
                story.append(bullet)
                story.append(Spacer(1, 0.1*inch))
        else:
            story.append(Paragraph("ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.", self.styles['CustomBody']))

        story.append(PageBreak())
        return story

    def _create_appendix(self, data: Dict[str, Any]) -> List:
        """ë¶€ë¡: í™˜ê° íƒì§€ ìƒì„¸ ê²°ê³¼."""
        story = []
        search_result = data['search_result']

        story.append(Paragraph("ë¶€ë¡. í™˜ê° íƒì§€ ìƒì„¸ ê²°ê³¼", self.styles['CustomHeading1']))
        story.append(Spacer(1, 0.2*inch))

        # í™˜ê° íƒì§€ ì‹œìŠ¤í…œ ì„¤ëª…
        explanation = """
ë³¸ ë³´ê³ ì„œì˜ ëª¨ë“  ì´ìŠˆëŠ” 3ë‹¨ê³„ AI í™˜ê° íƒì§€ ì‹œìŠ¤í…œì„ í†µí•´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤:
â€¢ RePPL (Relevant Paraphrased Prompt with Logit) íƒì§€ê¸°
â€¢ ìê¸° ì¼ê´€ì„± (Self-Consistency) ê²€ì‚¬
â€¢ LLM-as-Judge í‰ê°€
        """
        story.append(Paragraph(explanation.strip(), self.styles['CustomBody']))

        story.append(Spacer(1, 0.2*inch))

        # ì‹ ë¢°ë„ ë¶„í¬ ì°¨íŠ¸ (ê°„ë‹¨í•œ í…Œì´ë¸”ë¡œ ëŒ€ì²´)
        if hasattr(search_result, 'confidence_distribution'):
            dist = search_result.confidence_distribution
            dist_data = [
                ['ì‹ ë¢°ë„ ë“±ê¸‰', 'ì´ìŠˆ ìˆ˜', 'ë¹„ìœ¨'],
                ['ë†’ìŒ (70% ì´ìƒ)', f"{dist.get('high', 0)}ê°œ",
                 f"{dist.get('high', 0)/max(1, search_result.total_found)*100:.1f}%"],
                ['ì¤‘ê°„ (40-70%)', f"{dist.get('moderate', 0)}ê°œ",
                 f"{dist.get('moderate', 0)/max(1, search_result.total_found)*100:.1f}%"],
                ['ë‚®ìŒ (40% ë¯¸ë§Œ)', f"{dist.get('low', 0)}ê°œ",
                 f"{dist.get('low', 0)/max(1, search_result.total_found)*100:.1f}%"]
            ]

            dist_table = Table(dist_data, colWidths=[2*inch, 1.5*inch, 1.5*inch])
            dist_table.setStyle(TableStyle([
                ('FONTNAME', (0, 0), (-1, -1), self.default_font),
                ('FONTSIZE', (0, 0), (-1, -1), 10),
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#e74c3c')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#bdc3c7')),
            ]))

            story.append(dist_table)

        return story

    def _add_page_number(self, canvas_obj, doc):
        """í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€."""
        canvas_obj.saveState()
        canvas_obj.setFont(self.default_font, 9)
        canvas_obj.setFillColor(colors.HexColor('#7f8c8d'))

        page_num = canvas_obj.getPageNumber()
        if page_num > 1:  # í‘œì§€ ì œì™¸
            text = f"í˜ì´ì§€ {page_num - 1}"
            canvas_obj.drawRightString(
                doc.pagesize[0] - doc.rightMargin,
                doc.bottomMargin / 2,
                text
            )

        canvas_obj.restoreState()

    async def generate_report(self, search_result: SearchResult, topic: str) -> str:
        """
        ì „ì²´ PDF ë³´ê³ ì„œ ìƒì„± í”„ë¡œì„¸ìŠ¤.

        Args:
            search_result: ê²€ìƒ‰ ê²°ê³¼ ê°ì²´
            topic: ë³´ê³ ì„œ ì£¼ì œ

        Returns:
            str: ìƒì„±ëœ PDF íŒŒì¼ ê²½ë¡œ
        """
        try:
            # 1. LLMìœ¼ë¡œ ë‚´ìš© ê°œì„ 
            enhanced_data = await self.enhance_content_with_llm(search_result)

            # 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •
            reports_dir = "reports"
            os.makedirs(reports_dir, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_topic = "".join(c for c in topic if c.isalnum() or c in (' ', '-', '_')).rstrip()
            filename = f"report_{safe_topic}_{timestamp}_enhanced.pdf"
            file_path = os.path.join(reports_dir, filename)

            # 3. PDF ìƒì„±
            self.generate_pdf(enhanced_data, file_path)

            return file_path

        except Exception as e:
            logger.error(f"PDF ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise


# ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
async def create_pdf_report(search_result: SearchResult, topic: str) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¡œë¶€í„° PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.

    Args:
        search_result: ê²€ìƒ‰ ê²°ê³¼ ê°ì²´
        topic: ë³´ê³ ì„œ ì£¼ì œ

    Returns:
        str: ìƒì„±ëœ PDF íŒŒì¼ ê²½ë¡œ
    """
    generator = PDFReportGenerator()
    return await generator.generate_report(search_result, topic)