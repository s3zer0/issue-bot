"""
Grok (X/Twitter) ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸° - 500 ì—ëŸ¬ í•´ê²° ë²„ì „
"""

import asyncio
import time
import re
import json
from typing import List, Optional, Dict
from loguru import logger
import httpx

from ..base import BaseKeywordExtractor, KeywordExtractionResult, KeywordItem, KeywordImportance
from src.config import config


class GrokKeywordExtractor(BaseKeywordExtractor):
    """Grok APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ì¶œê¸°."""

    def __init__(self, api_key: Optional[str] = None):
        """Grok ì¶”ì¶œê¸° ì´ˆê¸°í™”."""
        # API í‚¤ ì„¤ì •: ì¸ìë¡œ ë°›ì€ í‚¤ê°€ ì—†ìœ¼ë©´ configì—ì„œ ê°€ì ¸ì˜´
        self.api_key = api_key or config.get_grok_api_key()
        super().__init__("Grok", self.api_key)

        # API ì„¤ì •
        self.base_url = "https://api.x.ai/v1/chat/completions"
        self.model = config.get_grok_model()
        self.timeout = config.get_grok_timeout()
        self.max_retries = 3

        # ì„œë¹„ìŠ¤ ìƒíƒœ ì¶”ì 
        self.service_status = "unknown"  # unknown, healthy, degraded, down
        self.consecutive_failures = 0
        self.last_success_time = None

        # API í‚¤ í™•ì¸ ë° ê°•ì œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì„¤ì •
        if not self.api_key or self.consecutive_failures >= 3:
            logger.warning("Grok API í‚¤ê°€ ì—†ê±°ë‚˜ ì—°ì† ì‹¤íŒ¨ë¡œ ì¸í•´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            self.simulation_mode = True
        else:
            logger.info("Grok API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.simulation_mode = False

        self.headers = {
            "Authorization": f"Bearer {self.api_key}" if self.api_key else "",
            "Content-Type": "application/json"
        }

        self.is_initialized = True
        logger.info(f"Grok í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {'ì‹œë®¬ë ˆì´ì…˜' if self.simulation_mode else 'ì‹¤ì œ API'})")

    async def extract_keywords(
        self,
        topic: str,
        context: Optional[str] = None,
        max_keywords: int = 20
    ) -> KeywordExtractionResult:
        """Grokì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        start_time = time.time()
        logger.info(f"Grok í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘: '{topic}'")

        try:
            # ì—°ì† ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ ìë™ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜
            if self.consecutive_failures >= 3:
                logger.warning(f"ì—°ì† {self.consecutive_failures}ë²ˆ ì‹¤íŒ¨ë¡œ ì¸í•´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜")
                self.simulation_mode = True

            if self.simulation_mode:
                keywords = await self._simulate_extraction(topic, context, max_keywords)
                raw_response = f"ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ì—°ì† ì‹¤íŒ¨: {self.consecutive_failures}íšŒ)"
            else:
                # ì‹¤ì œ API í˜¸ì¶œ ì‹œë„
                result = await self._real_extraction_with_fallback(topic, context, max_keywords)
                keywords = result['keywords']
                raw_response = result['raw_response']

            return KeywordExtractionResult(
                keywords=keywords,
                source_name=self.name,
                extraction_time=time.time() - start_time,
                raw_response=raw_response,
                metadata={
                    'mode': 'simulation' if self.simulation_mode else 'real_api',
                    'model': self.model if not self.simulation_mode else 'simulation',
                    'consecutive_failures': self.consecutive_failures,
                    'service_status': self.service_status
                }
            )

        except Exception as e:
            logger.error(f"Grok í‚¤ì›Œë“œ ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨: {e}")
            # ìµœì¢… í´ë°±: í•­ìƒ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜í™˜
            keywords = await self._simulate_extraction(topic, context, max_keywords)
            return KeywordExtractionResult(
                keywords=keywords,
                source_name=f"{self.name}_fallback",
                extraction_time=time.time() - start_time,
                error=str(e),
                raw_response="ìµœì¢… í´ë°± - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ",
                metadata={'mode': 'emergency_fallback', 'original_error': str(e)}
            )

    async def _real_extraction_with_fallback(
        self,
        topic: str,
        context: Optional[str],
        max_keywords: int
    ) -> Dict[str, any]:
        """í´ë°± ë©”ì»¤ë‹ˆì¦˜ì´ í¬í•¨ëœ ì‹¤ì œ API í˜¸ì¶œ."""

        # ì—¬ëŸ¬ ëª¨ë¸ê³¼ ì„¤ì • ì¡°í•© ì‹œë„
        api_configs = [
            {"model": "grok-3-latest", "search_params": False},
            {"model": "grok-3", "search_params": True},
            {"model": "grok-2-latest", "search_params": False},
        ]

        for config_idx, api_config in enumerate(api_configs):
            try:
                logger.info(f"Grok API ì„¤ì • {config_idx + 1}/{len(api_configs)} ì‹œë„: {api_config['model']}")

                prompt = self._build_simplified_prompt(topic, context, max_keywords)
                payload = self._build_safe_payload(prompt, api_config)

                result = await self._make_safe_api_call(payload)

                if result:
                    self.consecutive_failures = 0  # ì„±ê³µ ì‹œ ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
                    self.last_success_time = time.time()
                    self.service_status = "healthy"
                    logger.success(f"Grok API ì„±ê³µ: {api_config['model']}")
                    return result

            except Exception as e:
                logger.warning(f"API ì„¤ì • {config_idx + 1} ì‹¤íŒ¨: {e}")
                continue

        # ëª¨ë“  ì„¤ì • ì‹¤íŒ¨
        self.consecutive_failures += 1
        self.service_status = "down"

        # í´ë°±: ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì „í™˜
        logger.error("ëª¨ë“  Grok API ì„¤ì • ì‹¤íŒ¨. ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ í´ë°±.")
        keywords = await self._simulate_extraction(topic, context, max_keywords)
        return {
            'keywords': keywords,
            'raw_response': f"API ì‹¤íŒ¨ í›„ ì‹œë®¬ë ˆì´ì…˜ í´ë°± (ì‹¤íŒ¨ {self.consecutive_failures}íšŒ)"
        }

    def _build_safe_payload(self, prompt: str, api_config: dict) -> dict:
        """ì•ˆì „í•œ API í˜ì´ë¡œë“œ ìƒì„±."""
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": """You are a real-time trend analyst specializing in X (Twitter) and social media platforms.

**Role Specialization**: 
- Real-time social media trend monitoring and analysis
- Viral content pattern detection and hashtag tracking  
- Community conversation analysis across platforms
- Breaking news and emerging topic identification

**Core Capabilities**:
- Track trending hashtags and viral topics in real-time
- Identify emerging conversations before they go mainstream
- Analyze social sentiment and community engagement patterns
- Distinguish between organic trends and manufactured/promoted content

**Focus Areas**:
- X (Twitter) trending topics and hashtags
- Real-time news breaking on social platforms
- Community discussions and user-generated content
- Viral memes, phrases, and cultural moments

**Response Quality Standards**:
- Provide only trending keywords that are currently active
- Focus on social media native terminology and hashtags
- Exclude outdated or declining trends
- Prioritize organic, user-driven conversations over marketing content"""
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "model": api_config["model"],
            "max_tokens": 800,  # í† í° ìˆ˜ ì¤„ì„
            "temperature": 0.3,
        }

        # search_parametersëŠ” ì„ íƒì ìœ¼ë¡œë§Œ ì¶”ê°€
        if api_config.get("search_params", False):
            payload["search_parameters"] = {
                "mode": "auto"
            }

        return payload

    def _build_simplified_prompt(self, topic: str, context: Optional[str], max_keywords: int) -> str:
        """ì—­í•  íŠ¹í™”ëœ ê³ ê¸‰ Grok í”„ë¡¬í”„íŠ¸ ìƒì„±."""

        prompt = f"""As a real-time trend analyst focusing on X (Twitter), analyze current social media trends for: "{topic}"

**Chain-of-Thought Analysis**:

1. **Current Social Media Landscape Analysis**: 
   First, assess what's happening right now on X/Twitter related to this topic.
   - Are there active hashtag campaigns?
   - What breaking news or announcements are trending?
   - Which communities are actively discussing this?

2. **Trend Categorization**: Based on your analysis, extract keywords in these categories:

**ğŸ”¥ Viral Hashtags & Trending Topics** (5-7 keywords):
- Currently trending hashtags on X (Twitter)
- Viral phrases or memes related to the topic
- Breakout topics gaining rapid traction
- Real-time trending conversations

**ğŸ“° Breaking Social News** (5-7 keywords):
- News breaking first on social media
- Real-time updates and announcements  
- Live event coverage and reactions
- Time-sensitive developments

**ğŸ’¬ Community Conversations** (3-5 keywords):
- Active discussions in relevant communities
- User-generated content themes
- Sentiment-driven keywords
- Grassroots conversations and movements

**Quality Standards (Negative Prompting)**:
âŒ **EXCLUDE**:
- Generic marketing terms or promotional language
- Outdated trends or declining hashtags
- Bot-generated or manufactured trending topics
- Overly broad or non-specific social media terms

âœ… **INCLUDE**:
- Currently active and verified trending topics
- Authentic user-driven conversations
- Real-time hashtags with genuine engagement
- Social media native terminology

**Response Format (JSON)**:
{{
  "analysis": {{
    "trend_assessment": "Current state of social media trends for this topic",
    "key_platforms": ["X/Twitter", "other relevant platforms"],
    "trend_velocity": "rising/stable/declining"
  }},
  "trending": ["#hashtag1", "viral_topic1", "breakout_trend1", ...],
  "news": ["breaking_news1", "realtime_update1", "announcement1", ...],
  "discussion": ["community_topic1", "user_conversation1", "sentiment_trend1", ...]
}}"""

        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (Tier 2 ëª¨ë“œ)
        if context and "Tier 1 keywords for refinement:" in context:
            tier1_context = context.split("Tier 1 keywords for refinement:")[-1].strip()
            prompt += f"""

**Tier 1 Social Media Refinement**:
Previous keywords from other sources: {tier1_context}

**Social Media Enhancement Guidelines**:
- Verify which of these keywords are actually trending on social media
- Add missing viral hashtags or social conversations
- Update with current social media terminology
- Focus on real-time social media native expressions"""

        elif context:
            prompt += f"\n\n**Additional Context**: {context}"

        prompt += f"""

**Important**: Limit to {max_keywords} total keywords across all categories. Focus on currently active social media trends only."""

        return prompt

    async def _make_safe_api_call(self, payload: dict) -> Optional[Dict[str, any]]:
        """ì•ˆì „í•œ API í˜¸ì¶œ (ê°•í™”ëœ ì—ëŸ¬ ì²˜ë¦¬)."""

        for attempt in range(self.max_retries):
            try:
                timeout_config = httpx.Timeout(
                    connect=10.0,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ
                    read=self.timeout,  # ì½ê¸° íƒ€ì„ì•„ì›ƒ
                    write=10.0,  # ì“°ê¸° íƒ€ì„ì•„ì›ƒ
                    pool=30.0   # í’€ íƒ€ì„ì•„ì›ƒ
                )

                async with httpx.AsyncClient(
                    headers=self.headers,
                    timeout=timeout_config,
                    limits=httpx.Limits(max_connections=1)  # ì—°ê²° ì œí•œ
                ) as client:

                    logger.debug(f"Grok API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}")
                    response = await client.post(self.base_url, json=payload)

                    # ìƒíƒœ ì½”ë“œë³„ ìƒì„¸ ì²˜ë¦¬
                    if response.status_code == 200:
                        data = response.json()
                        content = data['choices'][0]['message']['content']
                        keywords = self._parse_grok_response(content, payload['messages'][1]['content'])

                        return {
                            'keywords': keywords,
                            'raw_response': content
                        }

                    elif response.status_code == 500:
                        self.service_status = "down"
                        logger.error(f"Grok API ì„œë²„ ì—ëŸ¬ 500 (ì‹œë„ {attempt + 1})")
                        logger.debug(f"500 ì—ëŸ¬ ì‘ë‹µ: {response.text[:300]}")

                        # 500 ì—ëŸ¬ëŠ” ì„œë²„ ë¬¸ì œì´ë¯€ë¡œ ê¸´ ëŒ€ê¸° í›„ ì¬ì‹œë„
                        if attempt < self.max_retries - 1:
                            wait_time = min(10 * (2 ** attempt), 60)  # ìµœëŒ€ 60ì´ˆ
                            logger.warning(f"ì„œë²„ ì—ëŸ¬ë¡œ ì¸í•´ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                            await asyncio.sleep(wait_time)

                    elif response.status_code == 429:
                        self.service_status = "degraded"
                        wait_time = 2 ** attempt
                        logger.warning(f"Rate limit. {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        if attempt < self.max_retries - 1:
                            await asyncio.sleep(wait_time)

                    elif response.status_code == 401:
                        logger.error("Grok API ì¸ì¦ ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                        self.simulation_mode = True  # ì¸ì¦ ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜
                        return None

                    elif response.status_code == 404:
                        logger.error("Grok API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•˜ì„¸ìš”.")
                        return None

                    else:
                        logger.error(f"Grok API ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                        logger.debug(f"ì‘ë‹µ ë‚´ìš©: {response.text[:300]}")
                        if attempt < self.max_retries - 1:
                            await asyncio.sleep(2 ** attempt)

            except httpx.TimeoutException:
                logger.warning(f"Grok API íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{self.max_retries})")
                if attempt < self.max_retries - 1:
                    wait_time = min(5 * (2 ** attempt), 30)
                    await asyncio.sleep(wait_time)

            except httpx.RequestError as e:
                logger.error(f"Grok API ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(3 ** attempt)

            except json.JSONDecodeError as e:
                logger.error(f"Grok API ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2)

        return None

    def _parse_grok_response(self, content: str, topic: str) -> List[KeywordItem]:
        """Grok ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„ ëœ íŒŒì‹±)."""
        keywords = []

        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())

                # ë‹¨ìˆœí™”ëœ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                category_mapping = {
                    'trending': ('trending', KeywordImportance.HIGH),
                    'news': ('realtime', KeywordImportance.HIGH),
                    'discussion': ('community', KeywordImportance.NORMAL),
                    # ê¸°ì¡´ í˜•ì‹ë„ ì§€ì›
                    'trending_hashtags': ('trending', KeywordImportance.HIGH),
                    'realtime_topics': ('realtime', KeywordImportance.HIGH),
                    'community_mentions': ('community', KeywordImportance.NORMAL),
                    'viral_keywords': ('viral', KeywordImportance.HIGH)
                }

                for category, keyword_list in data.items():
                    if category in category_mapping:
                        cat_name, importance = category_mapping[category]

                        for item in keyword_list:
                            if isinstance(item, dict) and 'keyword' in item:
                                # ìƒì„¸ ì •ë³´ê°€ ìˆëŠ” í˜•ì‹
                                keywords.append(KeywordItem(
                                    keyword=item['keyword'],
                                    sources=[self.name],
                                    importance=importance,
                                    confidence=item.get('confidence', 0.7),
                                    category=cat_name,
                                    metadata={
                                        'type': category,
                                        'trend_score': item.get('trend_score', 0.5),
                                        'reason': item.get('reason', ''),
                                        'source': 'grok_api'
                                    }
                                ))
                            elif isinstance(item, str):
                                # ë‹¨ìˆœ ë¬¸ìì—´ í˜•ì‹
                                keywords.append(KeywordItem(
                                    keyword=item,
                                    sources=[self.name],
                                    importance=importance,
                                    confidence=0.7,
                                    category=cat_name,
                                    metadata={'type': category, 'source': 'grok_api'}
                                ))
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„
                keywords = self._parse_text_response(content, topic)

        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"Grok ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ë°±ì—… íŒŒì‹± ì‹œë„
            keywords = self._parse_text_response(content, topic)

        return keywords[:20]  # ìµœëŒ€ 20ê°œë¡œ ì œí•œ

    def _parse_text_response(self, content: str, topic: str) -> List[KeywordItem]:
        """í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ë°±ì—… íŒŒì‹±)."""
        keywords = []
        lines = content.split('\n')

        current_category = 'general'
        for line in lines:
            line = line.strip()

            # ì¹´í…Œê³ ë¦¬ ê°ì§€
            if any(cat in line.lower() for cat in ['hashtag', 'trending', 'viral']):
                current_category = 'trending'
            elif any(cat in line.lower() for cat in ['realtime', 'news', 'latest']):
                current_category = 'realtime'
            elif any(cat in line.lower() for cat in ['community', 'discussion']):
                current_category = 'community'

            # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
            keyword_matches = re.findall(r'[#@]?\w+(?:\s+\w+)*', line)
            for match in keyword_matches:
                cleaned = match.strip()
                if len(cleaned) > 2 and cleaned.lower() not in ['the', 'and', 'for', 'with', 'are', 'you']:
                    keywords.append(KeywordItem(
                        keyword=cleaned,
                        sources=[self.name],
                        importance=KeywordImportance.NORMAL,
                        confidence=0.6,
                        category=current_category,
                        metadata={'type': 'text_parsed', 'source': 'grok_api'}
                    ))

        return keywords[:15]  # í…ìŠ¤íŠ¸ íŒŒì‹±ì€ ë” ì ê²Œ

    async def _simulate_extraction(
        self,
        topic: str,
        context: Optional[str],
        max_keywords: int
    ) -> List[KeywordItem]:
        """Grok í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë®¬ë ˆì´ì…˜ (ê°œì„ ëœ ë²„ì „)."""
        # ì‹¤ì‹œê°„ íŠ¸ë Œë“œë¥¼ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.3)  # API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜

        keyword_items = []
        base_topic = self.preprocess_topic(topic)
        current_year = "2025"

        # íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ (HIGH importance)
        trending_keywords = [
            f"#{base_topic}",
            f"{base_topic}_trending",
            f"{base_topic}{current_year}",
            f"breaking_{base_topic}",
            f"viral_{base_topic}"
        ]

        for kw in trending_keywords[:max_keywords // 3]:
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.HIGH,
                confidence=0.85,
                category='trending',
                metadata={'type': 'hashtag', 'trend_score': 0.9, 'source': 'simulation'}
            ))

        # ì‹¤ì‹œê°„ í† í”½ í‚¤ì›Œë“œ (NORMAL importance)
        realtime_keywords = [
            f"{base_topic} news",
            f"{base_topic} update",
            f"latest {base_topic}",
            f"{base_topic} development",
            f"recent {base_topic}"
        ]

        for kw in realtime_keywords[:max_keywords // 3]:
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.NORMAL,
                confidence=0.75,
                category='realtime',
                metadata={'type': 'topic', 'source': 'simulation'}
            ))

        # ì»¤ë®¤ë‹ˆí‹° ì–¸ê¸‰ í‚¤ì›Œë“œ (NORMAL to LOW)
        community_keywords = [
            f"{base_topic} discussion",
            f"{base_topic} community",
            f"{base_topic} opinion",
            f"{base_topic} analysis",
            f"{base_topic} insights"
        ]

        for kw in community_keywords[:max_keywords // 3]:
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.NORMAL,
                confidence=0.65,
                category='community',
                metadata={'type': 'discussion', 'source': 'simulation'}
            ))

        return keyword_items

    async def get_health_status(self) -> Dict[str, any]:
        """ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´ ë°˜í™˜."""
        return {
            'service_status': self.service_status,
            'simulation_mode': self.simulation_mode,
            'consecutive_failures': self.consecutive_failures,
            'last_success_time': self.last_success_time,
            'api_key_configured': bool(self.api_key),
            'recommendations': self._get_health_recommendations()
        }

    def _get_health_recommendations(self) -> List[str]:
        """ìƒíƒœ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­."""
        recommendations = []

        if self.consecutive_failures >= 3:
            recommendations.append("âŒ ì—°ì† ì‹¤íŒ¨ê°€ ë§ìŠµë‹ˆë‹¤. API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        if self.service_status == "down":
            recommendations.append("ğŸš¨ Grok API ì„œë¹„ìŠ¤ê°€ ë‹¤ìš´ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¶”ì¶œê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

        if self.simulation_mode:
            recommendations.append("ğŸ’¡ í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ íŠ¸ë Œë“œ ë°ì´í„°ê°€ í•„ìš”í•˜ë©´ API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        return recommendations