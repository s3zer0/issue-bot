"""
GPT ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸° - ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ ë²„ì „.
"""

import asyncio
import json
import re
import time
from typing import List, Optional, Dict
from loguru import logger
from openai import AsyncOpenAI

from src.config import config
from ..base import BaseKeywordExtractor, KeywordExtractionResult, KeywordItem, KeywordImportance


class GPTKeywordExtractor(BaseKeywordExtractor):
    """
    OpenAI GPTë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œê¸° - í–¥ìƒëœ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨.
    
    Features:
    - ðŸ†• GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì§€ì›
    - ðŸ” Perplexity API í†µí•© ê²€ìƒ‰  
    - ðŸŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëžµ (ë„¤ì´í‹°ë¸Œ + Perplexity)
    - âš¡ ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ ë° ì§€ëŠ¥ì  í´ë°±
    - ðŸŽ¯ ê²€ìƒ‰ ì „ëžµ ë™ì  ë³€ê²½ ê°€ëŠ¥
    """

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        """GPT ì¶”ì¶œê¸° ì´ˆê¸°í™”."""
        api_key = api_key or config.get_openai_api_key()
        super().__init__("GPT", api_key)

        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.model = model or config.get_openai_model()
        self.temperature = config.get_openai_temperature()
        self.max_tokens = config.get_openai_max_tokens()
        self.max_retries = config.get_max_retry_count()

        # ðŸ” ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
        self.perplexity_client = None
        self._initialize_search_client()
        
        # ðŸ†• GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì§€ì› í™•ì¸
        self.native_browsing_supported = self._check_native_browsing_support()
        self.search_strategy = "hybrid"  # "native", "perplexity", "hybrid"

        self.is_initialized = True
        search_status = self._get_search_status_message()
        logger.info(f"GPT í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model}, {search_status})")

    def _initialize_search_client(self):
        """Perplexity í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”."""
        try:
            from src.clients.perplexity_client import PerplexityClient
            self.perplexity_client = PerplexityClient()
            logger.info("ì›¹ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError:
            logger.warning("Perplexity í´ë¼ì´ì–¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        except Exception as e:
            logger.warning(f"ì›¹ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _check_native_browsing_support(self) -> bool:
        """GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì§€ì› ì—¬ë¶€ í™•ì¸."""
        # GPT-4o ëª¨ë¸ë“¤ì€ ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•ì„ ì§€ì›
        browse_supported_models = [
            "gpt-4o", "gpt-4o-2024-05-13", "gpt-4o-2024-08-06", 
            "gpt-4o-mini", "gpt-4o-mini-2024-07-18",
            "gpt-4-turbo", "gpt-4-turbo-2024-04-09"
        ]
        return any(model in self.model.lower() for model in browse_supported_models)

    def _get_search_status_message(self) -> str:
        """ê²€ìƒ‰ ê¸°ëŠ¥ ìƒíƒœ ë©”ì‹œì§€ ìƒì„±."""
        status_parts = []
        
        if self.native_browsing_supported:
            status_parts.append("GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•")
        
        if self.perplexity_client:
            status_parts.append("Perplexity ê²€ìƒ‰")
        
        if status_parts:
            return f"ì›¹ ê²€ìƒ‰: {' + '.join(status_parts)} í™œì„±í™” ({self.search_strategy})"
        else:
            return "ì›¹ ê²€ìƒ‰: ë¹„í™œì„±í™”"

    def _get_search_capabilities(self) -> Dict[str, bool]:
        """ê²€ìƒ‰ ê¸°ëŠ¥ ê°€ìš©ì„± ìƒíƒœ ë°˜í™˜."""
        return {
            'native_browsing': self.native_browsing_supported,
            'perplexity_search': self.perplexity_client is not None,
            'hybrid_search': self.native_browsing_supported or self.perplexity_client is not None
        }

    async def extract_keywords(
        self,
        topic: str,
        context: Optional[str] = None,
        max_keywords: int = 20
    ) -> KeywordExtractionResult:
        """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        start_time = time.time()
        logger.info(f"GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œìž‘: '{topic}'")

        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(topic, context, max_keywords)

            # ðŸ†• í–¥ìƒëœ ê²€ìƒ‰ ì „ëžµì— ë”°ë¥¸ API í˜¸ì¶œ
            if self.search_strategy == "hybrid" and (self.native_browsing_supported or self.perplexity_client):
                raw_response = await self._call_gpt_with_hybrid_search(prompt)
            elif self.search_strategy == "native" and self.native_browsing_supported:
                raw_response = await self._call_gpt_with_native_browse(prompt)
            elif self.search_strategy == "perplexity" and self.perplexity_client:
                raw_response = await self._call_gpt_with_search(prompt)
            else:
                raw_response = await self._call_gpt(prompt)

            # ì‘ë‹µ íŒŒì‹±
            keywords = self._parse_response(raw_response)

            # KeywordItem ê°ì²´ë¡œ ë³€í™˜
            keyword_items = self._create_keyword_items(keywords)

            return KeywordExtractionResult(
                keywords=keyword_items,
                source_name=self.name,
                extraction_time=time.time() - start_time,
                raw_response=raw_response,
                metadata={
                    'model': self.model,
                    'web_search_available': self.perplexity_client is not None,
                    'native_browsing_supported': self.native_browsing_supported,
                    'search_strategy': self.search_strategy,
                    'search_capabilities': self._get_search_capabilities()
                }
            )

        except Exception as e:
            logger.error(f"GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return KeywordExtractionResult(
                keywords=[],
                source_name=self.name,
                extraction_time=time.time() - start_time,
                error=str(e)
            )

    def _build_prompt(self, topic: str, context: Optional[str], max_keywords: int) -> str:
        """ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ ì ìš©ëœ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±."""
        
        # Chain-of-Thought (CoT) êµ¬ì¡°ë¡œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        base_prompt = f"""ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤. ê·€í•˜ì˜ ì—­í• ì€ ìµœì‹  ê¸°ìˆ  ë™í–¥ê³¼ ì •í™•í•œ ì „ë¬¸ ìš©ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ í’ˆì§ˆ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.

**ë¶„ì„ ì£¼ì œ**: "{topic}"

**ë‹¨ê³„ë³„ ë¶„ì„ ìˆ˜í–‰ (Chain-of-Thought)**:

1. **ì£¼ì œ ë¶„ì„ ë‹¨ê³„**: ë¨¼ì € ì´ ì£¼ì œì˜ í•µì‹¬ ì¸¡ë©´ë“¤ì„ ë¶„ì„í•´ë³´ì„¸ìš”.
   - ê¸°ìˆ ì  ì˜ì—­: ì–´ë–¤ ê¸°ìˆ  ë¶„ì•¼ì— ì†í•˜ëŠ”ê°€?
   - í˜„ìž¬ ìƒíƒœ: ì‹ ê¸°ìˆ ì¸ê°€, ê¸°ì¡´ ê¸°ìˆ ì˜ ë°œì „ì¸ê°€?
   - ì ìš© ë¶„ì•¼: ì–´ë–¤ ì‚°ì—…ì´ë‚˜ ì˜ì—­ì—ì„œ ì‚¬ìš©ë˜ëŠ”ê°€?

2. **í‚¤ì›Œë“œ í›„ë³´ ìƒì„±**: ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

**í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë° ìƒì„± ê·œì¹™**:

ðŸŽ¯ **í•µì‹¬ í‚¤ì›Œë“œ (Primary)** (5-7ê°œ):
- ì£¼ì œì˜ ë³¸ì§ˆì„ ì •í™•ížˆ í‘œí˜„í•˜ëŠ” ì „ë¬¸ ìš©ì–´
- ê³µì‹ ëª…ì¹­, í‘œì¤€ ìš©ì–´, ì—…ê³„ í‘œì¤€ ì‚¬ìš©
- ì˜ˆ: ì •í™•í•œ ê¸°ìˆ ëª…, APIëª…, í”„ë¡œí† ì½œëª…

ðŸ”— **ê´€ë ¨ ìš©ì–´ (Related)** (5-7ê°œ):
- êµ¬ì²´ì ì¸ êµ¬í˜„ì²´, ì œí’ˆëª…, íšŒì‚¬ëª…
- ë²„ì „ ì •ë³´, í”Œëž«í¼ë³„ êµ¬í˜„ì²´
- ê²½ìŸ ê¸°ìˆ ì´ë‚˜ ëŒ€ì•ˆ ì†”ë£¨ì…˜

ðŸŒ **ë§¥ë½ í‚¤ì›Œë“œ (Context)** (5-7ê°œ):
- ì‘ìš© ë¶„ì•¼, ì‚¬ìš© ì‚¬ë¡€
- ê´€ë ¨ ì‚°ì—…, ìƒíƒœê³„
- í˜„ìž¬ íŠ¸ë Œë“œ, ë¯¸ëž˜ ì „ë§

**ì—„ê²©í•œ í’ˆì§ˆ ê¸°ì¤€ (Negative Prompting)**:
âŒ **ì œì™¸í•  í‚¤ì›Œë“œ ìœ í˜•**:
- ë§ˆì¼€íŒ… ìš©ì–´ë‚˜ ê³¼ìž¥ëœ í‘œí˜„ ("í˜ì‹ ì ", "ìµœê³ ì˜", "ì™„ë²½í•œ")
- ì´ˆë³´ìž ëŒ€ìƒ ìš©ì–´ ("introduction", "basics", "tutorial", "ê°€ì´ë“œ")
- ëª¨í˜¸í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ìš©ì–´ ("ì†”ë£¨ì…˜", "ì‹œìŠ¤í…œ", "í”Œëž«í¼")
- í™•ì¸ë˜ì§€ ì•Šì€ ì¶”ì¸¡ì„± ìš©ì–´
- ê³¼ë„í•˜ê²Œ ì¼ë°˜ì ì¸ í˜•ìš©ì‚¬

âœ… **í¬í•¨í•  í‚¤ì›Œë“œ íŠ¹ì§•**:
- ì „ë¬¸ê°€ê°€ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ì •í™•í•œ ìš©ì–´
- ê²€ìƒ‰ ê°€ëŠ¥í•˜ê³  ê²€ì¦ ê°€ëŠ¥í•œ ì‹¤ì œ ìš©ì–´
- ê¸°ìˆ  ë¬¸ì„œë‚˜ ê³µì‹ ë°œí‘œì—ì„œ ì‚¬ìš©ë˜ëŠ” ìš©ì–´
- 2024-2025ë…„ í˜„ìž¬ ìœ íš¨í•œ ìµœì‹  ìš©ì–´

**ì‘ë‹µ í˜•ì‹ (JSON)**:
{{
    "analysis": {{
        "technical_domain": "ê¸°ìˆ  ì˜ì—­ ë¶„ì„",
        "key_aspects": ["í•µì‹¬ ì¸¡ë©´1", "í•µì‹¬ ì¸¡ë©´2", "í•µì‹¬ ì¸¡ë©´3"],
        "current_status": "í˜„ìž¬ ìƒíƒœ ë¶„ì„"
    }},
    "primary_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
    "related_terms": ["ìš©ì–´1", "ìš©ì–´2", ...],
    "context_keywords": ["ë§¥ë½1", "ë§¥ë½2", ...],
    "confidence": 0.0-1.0,
    "quality_check": {{
        "excluded_generic_terms": "ì œì™¸ëœ ì¼ë°˜ì  ìš©ì–´ë“¤",
        "verification_sources": "ê²€ì¦ ê°€ëŠ¥í•œ ì†ŒìŠ¤ë“¤"
    }}
}}"""

        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (Tier 2ì—ì„œ ì‚¬ìš©)
        if context and "Tier 1 keywords for refinement:" in context:
            tier1_context = context.split("Tier 1 keywords for refinement:")[-1].strip()
            base_prompt += f"""

**Tier 2 ì •ì œ ëª¨ë“œ í™œì„±í™”**:
Tier 1ì—ì„œ ìƒì„±ëœ í‚¤ì›Œë“œë“¤ì„ ì°¸ê³ í•˜ì—¬ ë” ì •êµí•˜ê³  ì „ë¬¸ì ì¸ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

**Tier 1 ì°¸ê³  í‚¤ì›Œë“œ**: {tier1_context}

**Tier 2 ì •ì œ ì§€ì¹¨**:
- Tier 1 í‚¤ì›Œë“œì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”
- ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ê´€ì ì˜ í‚¤ì›Œë“œ ì¶”ê°€
- ë” êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ìš©ì–´ë¡œ ëŒ€ì²´
- ìµœì‹  ê¸°ìˆ  ë™í–¥ ë°˜ì˜"""

        elif context:
            base_prompt += f"\n\n**ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸**: {context}"

        return base_prompt

    async def _call_gpt(self, prompt: str) -> str:
        """ê¸°ë³¸ GPT API í˜¸ì¶œ (ì›¹ ê²€ìƒ‰ ì—†ìŒ)."""
        for attempt in range(self.max_retries):
            try:
                request_params = {
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": """ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤. 

**ì „ë¬¸ ì˜ì—­**: ìµœì‹  ê¸°ìˆ  ë™í–¥, ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ, AI/ML, í´ë¼ìš°ë“œ, ëª¨ë°”ì¼, ì›¹ ê¸°ìˆ  ë“±
**í•µì‹¬ ëŠ¥ë ¥**: 
- ê³µì‹ ê¸°ìˆ  ë¬¸ì„œì™€ API ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„
- ì—…ê³„ í‘œì¤€ ìš©ì–´ì™€ ì‹¤ë¬´ì§„ì´ ì‚¬ìš©í•˜ëŠ” ì •í™•í•œ ì „ë¬¸ ìš©ì–´ êµ¬ë¶„
- ë§ˆì¼€íŒ… ìš©ì–´ì™€ ê¸°ìˆ ì  ì •í™•ì„±ì„ ê°€ì§„ ìš©ì–´ êµ¬ë¶„
- ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œì™€ ë ˆê±°ì‹œ ê¸°ìˆ ì˜ í˜„ìž¬ ìƒíƒœ íŒŒì•…

**ì‘ë‹µ ì›ì¹™**: 
- í•­ìƒ ê²€ì¦ ê°€ëŠ¥í•œ ì‹¤ì œ ê¸°ìˆ  ìš©ì–´ë§Œ ì‚¬ìš©
- ì¶”ì¸¡ì´ë‚˜ ì°½ìž‘ ê¸ˆì§€
- ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
- Chain-of-Thought ë¶„ì„ ê³¼ì • í¬í•¨"""
                        },
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": self.temperature,
                    "max_tokens": self.max_tokens
                }

                # GPT-4 ëª¨ë¸ì˜ ê²½ìš° JSON ëª¨ë“œ í™œì„±í™”
                if "gpt-4" in self.model:
                    request_params["response_format"] = {"type": "json_object"}

                response = await self.client.chat.completions.create(**request_params)
                return response.choices[0].message.content.strip()

            except Exception as e:
                logger.warning(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def _call_gpt_with_search(self, prompt: str) -> str:
        """ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì´ í¬í•¨ëœ GPT API í˜¸ì¶œ."""

        # ì›¹ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜
        search_function = {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "ìµœì‹  ì •ë³´ë‚˜ ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•  ë•Œ ì›¹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "ê²€ìƒ‰í•  í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸"
                        }
                    },
                    "required": ["query"]
                }
            }
        }

        for attempt in range(self.max_retries):
            try:
                # ì²« ë²ˆì§¸ GPT í˜¸ì¶œ (ê²€ìƒ‰ í•¨ìˆ˜ í¬í•¨)
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": """ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

**ì—­í•  íŠ¹í™”**: ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì‹¤ì‹œê°„ ì •ë³´ ìˆ˜ì§‘ ë° ê²€ì¦
**ì£¼ìš” ìž„ë¬´**:
- ìµœì‹  ê¸°ìˆ  ë™í–¥, ì œí’ˆ ì¶œì‹œ, ì—…ë°ì´íŠ¸ ì •ë³´ ì‹¤ì‹œê°„ í™•ì¸
- ê³µì‹ ë°œí‘œ, ê¸°ìˆ  ë¬¸ì„œ, API ë³€ê²½ì‚¬í•­ ì¶”ì 
- ì •í™•í•œ ë²„ì „ ì •ë³´, ì œí’ˆëª…, ê¸°ìˆ  ì‚¬ì–‘ ê²€ì¦

**ì›¹ ê²€ìƒ‰ í™œìš© ì§€ì¹¨**:
- ë¶ˆí™•ì‹¤í•œ ìµœì‹  ì •ë³´ëŠ” ë°˜ë“œì‹œ web_search í•¨ìˆ˜ ì‚¬ìš©
- ì œí’ˆëª…, ë²„ì „, ì¶œì‹œì¼ ë“±ì€ ê³µì‹ ì†ŒìŠ¤ì—ì„œ í™•ì¸
- ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìµœì‹ ì˜ í‚¤ì›Œë“œ ìƒì„±

**ìµœì¢… ì‘ë‹µ**: ìœ íš¨í•œ JSON í˜•ì‹, Chain-of-Thought ë¶„ì„ í¬í•¨"""
                        },
                        {"role": "user", "content": prompt}
                    ],
                    tools=[search_function],
                    tool_choice="auto",
                    temperature=self.temperature,
                    max_tokens=self.max_tokens
                )

                message = response.choices[0].message

                # Function callì´ ìžˆëŠ”ì§€ í™•ì¸
                if message.tool_calls:
                    logger.debug(f"GPTê°€ ì›¹ ê²€ìƒ‰ ìš”ì²­: {len(message.tool_calls)}ê°œ ê²€ìƒ‰")

                    # Performance: Parallel web search execution
                    messages = [
                        {
                            "role": "system",
                            "content": """ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

**í˜„ìž¬ ìƒí™©**: ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… í‚¤ì›Œë“œ ìƒì„±
**í•µì‹¬ ì›ì¹™**:
- ê²€ìƒ‰ìœ¼ë¡œ í™•ì¸ëœ ì •í™•í•œ ì •ë³´ë§Œ ì‚¬ìš©
- ìµœì‹ ì„±ê³¼ ì •í™•ì„±ì´ ê²€ì¦ëœ ìš©ì–´ ìš°ì„ 
- ê³µì‹ ëª…ì¹­ê³¼ í‘œì¤€ ìš©ì–´ ì‚¬ìš©
- ì¶”ì¸¡ì´ë‚˜ ë¶ˆí™•ì‹¤í•œ ì •ë³´ ë°°ì œ

**ìµœì¢… ì‘ë‹µ**: JSON í˜•ì‹, ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì‹ ë¢°ë„ ë°˜ì˜"""
                        },
                        {"role": "user", "content": prompt},
                        message
                    ]

                    # Performance: Collect all search tasks for parallel execution
                    search_tasks = []
                    tool_call_mapping = {}
                    
                    for tool_call in message.tool_calls:
                        if tool_call.function.name == "web_search":
                            args = json.loads(tool_call.function.arguments)
                            query = args.get("query", "")
                            
                            logger.debug(f"ì›¹ ê²€ìƒ‰ ì¤€ë¹„: {query}")
                            search_task = self._perform_web_search(query)
                            search_tasks.append(search_task)
                            tool_call_mapping[len(search_tasks) - 1] = tool_call

                    # Performance: Execute all searches in parallel
                    if search_tasks:
                        search_results = await asyncio.gather(*search_tasks, return_exceptions=True)
                        
                        # Add all search results to messages
                        for i, (search_result, tool_call) in enumerate(zip(search_results, tool_call_mapping.values())):
                            if not isinstance(search_result, Exception):
                                messages.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": search_result
                                })
                            else:
                                logger.warning(f"Web search failed: {search_result}")
                                messages.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(search_result)}"
                                })

                    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ìµœì¢… ì‘ë‹µ ìƒì„±
                    final_response = await self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        temperature=self.temperature,
                        max_tokens=self.max_tokens
                    )

                    return final_response.choices[0].message.content.strip()
                else:
                    # ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ì‘ë‹µ
                    return message.content.strip()

            except Exception as e:
                logger.warning(f"GPT Function Call API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ í´ë°±
                    logger.warning("ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ GPT í˜¸ì¶œë¡œ í´ë°±")
                    return await self._call_gpt(prompt)
                await asyncio.sleep(2 ** attempt)

    async def _call_gpt_with_native_browse(self, prompt: str) -> str:
        """ðŸ†• GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•ì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ."""
        
        # ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•ìš© í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
        browsing_prompt = f"""ë‹¹ì‹ ì€ ì›¹ ë¸Œë¼ìš°ì§• ê¸°ëŠ¥ì„ ê°€ì§„ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

**ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì—­í• **:
- ì‹¤ì‹œê°„ ì›¹ ì •ë³´ë¥¼ ì§ì ‘ ê²€ìƒ‰í•˜ê³  ë¶„ì„
- ê³µì‹ ë¬¸ì„œ, ê¸°ìˆ  ë¸”ë¡œê·¸, ìµœì‹  ë°œí‘œ ìžë£Œ ì ‘ê·¼
- ì •í™•í•œ ë²„ì „ ì •ë³´, ì¶œì‹œì¼, ê¸°ìˆ  ì‚¬ì–‘ ì‹¤ì‹œê°„ í™•ì¸

**ë¸Œë¼ìš°ì§• ì§€ì¹¨**:
1. ë¨¼ì € ì£¼ì œì™€ ê´€ë ¨ëœ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ë‚˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
2. ìµœì‹  ê¸°ìˆ  ë™í–¥ì´ë‚˜ ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ ì°¾ì•„ë³´ì„¸ìš”  
3. ì •í™•í•œ ì œí’ˆëª…, ë²„ì „, API ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”
4. ê²€ìƒ‰í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”

**ì›ë³¸ ìš”ì²­**:
{prompt}

**ì¤‘ìš”**: ì›¹ ê²€ìƒ‰ì„ í†µí•´ í™•ì¸í•œ ìµœì‹  ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”."""

        for attempt in range(self.max_retries):
            try:
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": """ë‹¹ì‹ ì€ ì›¹ ë¸Œë¼ìš°ì§• ê¸°ëŠ¥ì„ ê°€ì§„ ê¸°ìˆ  ë¶„ì•¼ ì „ë¬¸ í‚¤ì›Œë“œ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

**ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• íŠ¹í™” ì—­í• **:
- ì‹¤ì‹œê°„ ì›¹ ì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„ ì „ë¬¸ê°€
- ê³µì‹ ë¬¸ì„œì™€ ê¸°ìˆ  ì‚¬ì–‘ì„œ ì§ì ‘ ì ‘ê·¼ ë° ë¶„ì„
- ìµœì‹  ê¸°ìˆ  ë™í–¥ê³¼ ì—…ë°ì´íŠ¸ ì •ë³´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ì •í™•í•œ ê¸°ìˆ  ìš©ì–´ì™€ ê³µì‹ ëª…ì¹­ ê²€ì¦

**í•µì‹¬ ëŠ¥ë ¥**:
- ì§ì ‘ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘
- ê³µì‹ API ë¬¸ì„œì™€ ë¦´ë¦¬ìŠ¤ ë…¸íŠ¸ ë¶„ì„
- ê¸°ìˆ  ë¸”ë¡œê·¸ì™€ ê°œë°œìž í¬ëŸ¼ ëª¨ë‹ˆí„°ë§
- ë²„ì „ ì •ë³´ì™€ í˜¸í™˜ì„± ë°ì´í„° ì‹¤ì‹œê°„ í™•ì¸

**ì‘ë‹µ ì›ì¹™**: 
- ì›¹ ë¸Œë¼ìš°ì§•ìœ¼ë¡œ í™•ì¸í•œ ìµœì‹  ì •ë³´ë§Œ ì‚¬ìš©
- ê²€ìƒ‰í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
- ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
- ë¸Œë¼ìš°ì§• ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ë¶„ì„ì— í¬í•¨"""
                        },
                        {"role": "user", "content": browsing_prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=self.max_tokens
                )
                
                logger.debug("GPT-4o ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì™„ë£Œ")
                return response.choices[0].message.content.strip()

            except Exception as e:
                logger.warning(f"GPT ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    # ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ë²•ìœ¼ë¡œ í´ë°±
                    logger.warning("ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• ì‹¤íŒ¨, ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                    if self.perplexity_client:
                        return await self._call_gpt_with_search(prompt)
                    else:
                        return await self._call_gpt(prompt)
                await asyncio.sleep(2 ** attempt)

    async def _call_gpt_with_hybrid_search(self, prompt: str) -> str:
        """ðŸ†• í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëžµ: ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§• + Perplexity ê²€ìƒ‰."""
        
        # ê²€ìƒ‰ ì „ëžµ ê²°ì •
        search_tasks = []
        search_methods = []
        
        # ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•ì´ ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
        if self.native_browsing_supported:
            search_tasks.append(self._call_gpt_with_native_browse(prompt))
            search_methods.append("native_browsing")
        
        # Perplexity ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
        if self.perplexity_client:
            search_tasks.append(self._call_gpt_with_search(prompt))
            search_methods.append("perplexity_search")
        
        if not search_tasks:
            # ê²€ìƒ‰ ë°©ë²•ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ GPT í˜¸ì¶œ
            return await self._call_gpt(prompt)
        
        try:
            # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ (íƒ€ìž„ì•„ì›ƒ ì„¤ì •)
            logger.debug(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìž‘: {search_methods}")
            
            # ì½”ë£¨í‹´ì„ íƒœìŠ¤í¬ë¡œ ë³€í™˜
            tasks = [asyncio.create_task(task) for task in search_tasks]
            
            # ì²« ë²ˆì§¸ ì„±ê³µí•˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš© (ë” ë¹ ë¥¸ ì‘ë‹µ)
            done, pending = await asyncio.wait(
                tasks, 
                return_when=asyncio.FIRST_COMPLETED,
                timeout=120  # 2ë¶„ íƒ€ìž„ì•„ì›ƒ
            )
            
            # ì™„ë£Œë˜ì§€ ì•Šì€ íƒœìŠ¤í¬ ì·¨ì†Œ
            for task in pending:
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
            
            # ì²« ë²ˆì§¸ ì„±ê³µ ê²°ê³¼ ë°˜í™˜
            if done:
                completed_task = list(done)[0]
                result = await completed_task
                
                # ì–´ë–¤ ë°©ë²•ì´ ì„±ê³µí–ˆëŠ”ì§€ ì°¾ê¸°
                task_index = tasks.index(completed_task)
                successful_method = search_methods[task_index]
                logger.success(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ê³µ: {successful_method}")
                return result
            else:
                logger.warning("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ íƒ€ìž„ì•„ì›ƒ, ê¸°ë³¸ GPTë¡œ í´ë°±")
                return await self._call_gpt(prompt)
                
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ GPT í˜¸ì¶œ
            return await self._call_gpt(prompt)

    async def _perform_web_search(self, query: str) -> str:
        """ì‹¤ì œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰."""
        try:
            if self.perplexity_client:
                # Perplexity APIë¡œ ê²€ìƒ‰
                result = await self.perplexity_client._make_api_call(
                    f"{query}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ê³µì‹ ë°œí‘œ ë‚´ìš©ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”. "
                    f"íŠ¹ížˆ ì •í™•í•œ ì œí’ˆëª…, ë²„ì „, ì¶œì‹œì¼, ê¸°ìˆ  ì‚¬ì–‘ ë“±ì„ í¬í•¨í•´ì£¼ì„¸ìš”."
                )
                return f"ê²€ìƒ‰ ê²°ê³¼: {result}"
            else:
                return f"ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ: {query}"

        except Exception as e:
            logger.warning(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return f"ê²€ìƒ‰ ì‹¤íŒ¨: {query} (ì˜¤ë¥˜: {str(e)})"

    def _parse_response(self, raw_response: str) -> dict:
        """GPT ì‘ë‹µ íŒŒì‹±."""
        try:
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', raw_response, re.DOTALL)
            if not json_match:
                raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            data = json.loads(json_match.group())

            # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
            data.setdefault("primary_keywords", [])
            data.setdefault("related_terms", [])
            data.setdefault("context_keywords", [])
            data.setdefault("confidence", 0.8)

            return data

        except Exception as e:
            logger.error(f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"ì›ë³¸ ì‘ë‹µ: {raw_response}")

            # í´ë°±: ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "primary_keywords": [self.preprocess_topic(raw_response.split()[0]) if raw_response else "í‚¤ì›Œë“œ"],
                "related_terms": [],
                "context_keywords": [],
                "confidence": 0.3
            }

    def _create_keyword_items(self, parsed_data: dict) -> List[KeywordItem]:
        """íŒŒì‹±ëœ ë°ì´í„°ë¥¼ KeywordItem ê°ì²´ë¡œ ë³€í™˜."""
        keyword_items = []
        confidence = float(parsed_data.get('confidence', 0.8))

        # Primary keywords - HIGH importance
        for kw in parsed_data.get('primary_keywords', []):
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.HIGH,
                confidence=confidence,
                category='primary'
            ))

        # Related terms - NORMAL importance
        for kw in parsed_data.get('related_terms', []):
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.NORMAL,
                confidence=confidence * 0.9,
                category='related'
            ))

        # Context keywords - NORMAL to LOW importance
        for kw in parsed_data.get('context_keywords', []):
            keyword_items.append(KeywordItem(
                keyword=kw,
                sources=[self.name],
                importance=KeywordImportance.NORMAL,
                confidence=confidence * 0.8,
                category='context'
            ))

        return keyword_items

    def set_search_strategy(self, strategy: str) -> bool:
        """ðŸ†• ê²€ìƒ‰ ì „ëžµ ì„¤ì •.
        
        Args:
            strategy: "native", "perplexity", "hybrid" ì¤‘ í•˜ë‚˜
            
        Returns:
            bool: ì„¤ì • ì„±ê³µ ì—¬ë¶€
        """
        valid_strategies = ["native", "perplexity", "hybrid"]
        
        if strategy not in valid_strategies:
            logger.error(f"ìž˜ëª»ëœ ê²€ìƒ‰ ì „ëžµ: {strategy}. ìœ íš¨í•œ ê°’: {valid_strategies}")
            return False
        
        # ì „ëžµ ì‹¤í–‰ ê°€ëŠ¥ì„± í™•ì¸
        if strategy == "native" and not self.native_browsing_supported:
            logger.warning("ë„¤ì´í‹°ë¸Œ ë¸Œë¼ìš°ì§•ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ìž…ë‹ˆë‹¤. ì „ëžµì„ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        if strategy == "perplexity" and not self.perplexity_client:
            logger.warning("Perplexity í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ëžµì„ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        old_strategy = self.search_strategy
        self.search_strategy = strategy
        logger.info(f"ê²€ìƒ‰ ì „ëžµ ë³€ê²½: {old_strategy} â†’ {strategy}")
        return True

    def get_search_info(self) -> Dict[str, any]:
        """ðŸ†• í˜„ìž¬ ê²€ìƒ‰ ì„¤ì • ì •ë³´ ë°˜í™˜."""
        return {
            'current_strategy': self.search_strategy,
            'capabilities': self._get_search_capabilities(),
            'native_browsing_model': self.native_browsing_supported,
            'model': self.model,
            'status_message': self._get_search_status_message()
        }