"""
RePPL (Repetition as Pre-Perplexity) ê¸°ë°˜ í™˜ê° íƒì§€ê¸°.

í…ìŠ¤íŠ¸ì˜ ë°˜ë³µì„±, Perplexity, ì˜ë¯¸ì  ì—”íŠ¸ë¡œí”¼ë¥¼ ë¶„ì„í•˜ì—¬
LLM ì‘ë‹µì˜ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
"""

import re
import numpy as np
import math
from typing import List, Tuple, Optional
from collections import Counter
from loguru import logger
from sentence_transformers import SentenceTransformer
from openai import AsyncOpenAI
from sklearn.metrics.pairwise import cosine_similarity

from src.config import config
from .base import BaseHallucinationDetector
from .models import RePPLScore


class RePPLDetector(BaseHallucinationDetector):
    """RePPL ê¸°ë°˜ í™˜ê° íƒì§€ê¸° êµ¬í˜„."""

    def __init__(self, model_name: Optional[str] = None):
        """
        RePPL íƒì§€ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            model_name (Optional[str]): Perplexity ê³„ì‚°ì— ì‚¬ìš©í•  OpenAI ëª¨ë¸
        """
        super().__init__("RePPL")

        self.api_key = config.get_openai_api_key()
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.perplexity_model = model_name or "gpt-4o"
        # ğŸš€ ì „ì—­ ìºì‹œë¥¼ í†µí•œ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ìµœì í™”
        from src.hallucination_detection.enhanced_searcher import GlobalModelCache
        model_cache = GlobalModelCache()
        self.sentence_model = model_cache.get_model('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.repetition_threshold = 0.3
        self.perplexity_threshold = 50
        self.is_initialized = True
        logger.info(f"RePPL íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ (Perplexity ëª¨ë¸: {self.perplexity_model})")

    async def analyze_text(self, text: str, context: Optional[str] = None) -> RePPLScore:
        """í…ìŠ¤íŠ¸ì— ëŒ€í•´ RePPL ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        logger.debug(f"RePPL ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)})")
        repetition_score, repeated_phrases = self._analyze_repetition(text)
        perplexity = await self._calculate_perplexity_with_gpt(text, context)
        semantic_entropy = self._calculate_semantic_entropy(text)
        confidence = self._calculate_confidence_score(repetition_score, perplexity, semantic_entropy)

        logger.debug(
            f"RePPL ë¶„ì„ ì™„ë£Œ - ë°˜ë³µì„±: {repetition_score:.2f}, "
            f"PPL: {perplexity:.2f}, ì—”íŠ¸ë¡œí”¼: {semantic_entropy:.2f}, "
            f"ì‹ ë¢°ë„: {confidence:.2f}"
        )
        analysis_details = {
            "token_count": len(text.split()), "sentence_count": len(text.split('.')),
            "has_context": context is not None,
            "thresholds": {"repetition": self.repetition_threshold, "perplexity": self.perplexity_threshold}
        }
        return RePPLScore(
            confidence=confidence, repetition_score=repetition_score, perplexity=perplexity,
            semantic_entropy=semantic_entropy, repeated_phrases=repeated_phrases, analysis_details=analysis_details
        )

    def _analyze_repetition(self, text: str) -> Tuple[float, List[str]]:
        """
        í…ìŠ¤íŠ¸ ë‚´ n-gramì˜ ë°˜ë³µ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì¤‘ë³µ ê³„ì‚°ì„ í”¼í•˜ê¸° ìœ„í•´
        ë°˜ë³µë˜ëŠ” ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.
        """
        cleaned_text = re.sub(r'[^\w\s]', '', text.lower())
        words = cleaned_text.split()
        if len(words) < 3:
            return 0.0, []

        repeated_indices = set()
        all_repeated_phrases = set()

        for n in range(min(len(words), 7), 2, -1):
            ngrams = [' '.join(words[i:i + n]) for i in range(len(words) - n + 1)]
            counts = Counter(ngrams)

            for phrase, count in counts.items():
                if count > 1:
                    all_repeated_phrases.add(phrase)
                    # ì´ êµ¬ë¬¸ì´ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë“  ìœ„ì¹˜ì˜ ì¸ë±ìŠ¤ë¥¼ ê¸°ë¡
                    for i in range(len(words) - n + 1):
                        if ' '.join(words[i:i + n]) == phrase:
                            for j in range(n):
                                repeated_indices.add(i + j)

        repetition_score = len(repeated_indices) / len(words) if words else 0.0
        logger.debug(f"ë°˜ë³µì„± ë¶„ì„: ì ìˆ˜={repetition_score:.3f}, ë°˜ë³µ êµ¬ë¬¸={len(all_repeated_phrases)}ê°œ")
        return repetition_score, sorted(list(all_repeated_phrases), key=len, reverse=True)

    async def _calculate_perplexity_with_gpt(self, text: str, context: Optional[str] = None) -> float:
        """OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ Perplexityë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not text.strip(): return self.perplexity_threshold * 2
        try:
            full_text = f"Context: {context}\n\nText: {text}" if context else text
            response = await self.client.chat.completions.create(
                model=self.perplexity_model, messages=[{"role": "user", "content": full_text}],
                max_tokens=2048, temperature=0, logprobs=True
            )
            logprobs = [t.logprob for t in response.choices[0].logprobs.content if t.logprob is not None]
            if not logprobs: return self.perplexity_threshold * 2
            return math.exp(-sum(logprobs) / len(logprobs))
        except Exception as e:
            logger.error(f"Perplexity ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self.perplexity_threshold * 2

    def _calculate_semantic_entropy(self, text: str) -> float:
        """ë¬¸ì¥ ê°„ ì˜ë¯¸ì  ë‹¤ì–‘ì„±(ì—”íŠ¸ë¡œí”¼)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 5]
        if len(sentences) < 2: return 0.0
        embeddings = self.sentence_model.encode(sentences)
        sim_matrix = cosine_similarity(embeddings)
        if sim_matrix.shape[0] <= 1: return 0.0
        np.fill_diagonal(sim_matrix, 0)
        avg_similarity = np.sum(sim_matrix) / (len(sentences) * (len(sentences) - 1))
        return 1 - avg_similarity

    def _calculate_confidence_score(self, repetition: float, perplexity: float, entropy: float) -> float:
        """ê°œë³„ ì ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        rep_score = 1 - min(1.0, repetition / self.repetition_threshold)
        ppl_score = max(0.0, 1 - (perplexity / self.perplexity_threshold))
        ent_score = min(1.0, entropy)
        weights = {'repetition': 0.4, 'perplexity': 0.3, 'entropy': 0.3}
        confidence = (weights['repetition'] * rep_score + weights['perplexity'] * ppl_score + weights['entropy'] * ent_score)
        return round(confidence, 3)
