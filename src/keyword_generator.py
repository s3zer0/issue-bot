"""
í‚¤ì›Œë“œ ìƒì„± ëª¨ë“ˆ
LLMì„ í™œìš©í•˜ì—¬ ì£¼ì œ ê¸°ë°˜ í‚¤ì›Œë“œë¥¼ ìë™ ìƒì„±
"""

import asyncio
import json
import re
import time
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from loguru import logger

try:
    from openai import AsyncOpenAI, AuthenticationError
except ImportError:
    logger.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    class AsyncOpenAI: pass
    class AuthenticationError(Exception): pass

from src.config import config


@dataclass
class KeywordResult:
    """í‚¤ì›Œë“œ ìƒì„± ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (synonyms í•„ë“œ ì œê±°)"""
    topic: str
    primary_keywords: List[str]
    related_terms: List[str]
    context_keywords: List[str]
    confidence_score: float
    generation_time: float
    raw_response: str


class KeywordGenerator:
    """LLM ê¸°ë°˜ í‚¤ì›Œë“œ ìƒì„±ê¸°"""

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        self.api_key = api_key or config.get_openai_api_key()
        self.model = model or config.get_openai_model()

        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.max_retries = config.get_max_retry_count()
        self.timeout = config.get_keyword_generation_timeout()
        self.temperature = config.get_openai_temperature()
        self.max_tokens = config.get_openai_max_tokens()
        logger.info(f"KeywordGenerator ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model})")

    async def generate_keywords(
        self,
        topic: str,
        context: Optional[str] = None,
        num_keywords: int = 15
    ) -> KeywordResult:
        """ì£¼ì œì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        start_time = time.time()
        logger.info(f"í‚¤ì›Œë“œ ìƒì„± ì‹œì‘: '{topic}' (ëª¨ë¸: {self.model})")

        if not topic or not topic.strip():
            raise ValueError("ì£¼ì œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        topic = topic.strip()

        try:
            prompt = self._build_prompt(topic, context, num_keywords)
            raw_response = await self._call_llm(prompt)
            keyword_result = self._parse_response(topic, raw_response, time.time() - start_time)

            logger.success(
                f"í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ: {len(keyword_result.primary_keywords)}ê°œ í•µì‹¬ í‚¤ì›Œë“œ, "
                f"ì‹ ë¢°ë„ {keyword_result.confidence_score:.2f}, "
                f"ì†Œìš”ì‹œê°„ {keyword_result.generation_time:.1f}ì´ˆ"
            )
            return keyword_result
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def _build_prompt(self, topic: str, context: Optional[str], num_keywords: int) -> str:
        base_prompt = f"""ì£¼ì œ "{topic}"ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ê¸°ìˆ ì ì¸ ì´ìŠˆ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        **í•µì‹¬ ìš”êµ¬ì‚¬í•­:**
        1. í•´ë‹¹ ë¶„ì•¼ì˜ ìµœì‹  ê¸°ìˆ  ìš©ì–´, ì œí’ˆëª…, ì„œë¹„ìŠ¤ëª…, í‘œì¤€ ê·œê²©ì„ êµ¬ì²´ì ìœ¼ë¡œ í¬í•¨
        2. 2024ë…„ í˜„ì¬ ì—…ê³„ì—ì„œ ì‹¤ì œë¡œ ë…¼ì˜ë˜ëŠ” êµ¬ì²´ì ì¸ ì´ìŠˆì™€ íŠ¸ë Œë“œ ë°˜ì˜
        3. ì¼ë°˜ì ì¸ ìš©ì–´ë³´ë‹¤ëŠ” ë²„ì „ëª…, ëª¨ë¸ëª…, CVE ë²ˆí˜¸, í”„ë¡œí† ì½œëª… ë“± ê²€ìƒ‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ìš©ì–´ ì‚¬ìš©
        4. ì£¼ìš” ê¸°ì—…, ì—°êµ¬ ê¸°ê´€, ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸, í‘œì¤€í™” ê¸°êµ¬ ë“±ì˜ ê³ ìœ ëª…ì‚¬ í¬í•¨

        **í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬:**
        1. **í•µì‹¬ í‚¤ì›Œë“œ (Primary Keywords)**: 
           - ì£¼ì œì˜ í•µì‹¬ ê¸°ìˆ ëª…, ìµœì‹  ë²„ì „, ì£¼ìš” í”Œë«í¼
           - ì—…ê³„ í‘œì¤€ ìš©ì–´ì™€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì•½ì–´
           - {max(4, num_keywords // 3)}~{min(7, num_keywords // 2)}ê°œ

        2. **ê´€ë ¨ ìš©ì–´ (Related Terms)**: 
           - êµ¬ì²´ì ì¸ ì œí’ˆëª…, ë„êµ¬, í”„ë ˆì„ì›Œí¬, ë¼ì´ë¸ŒëŸ¬ë¦¬
           - ì£¼ìš” ê¸°ì—…ëª…, ì—°êµ¬ ê·¸ë£¹, ê°œë°œì, ì»¤ë®¤ë‹ˆí‹°
           - ìµœì‹  ì·¨ì•½ì , ê³µê²© ê¸°ë²•, ë³´ì•ˆ ë„êµ¬ (ë³´ì•ˆ ê´€ë ¨ ì£¼ì œì˜ ê²½ìš°)
           - {max(4, num_keywords // 3)}~{min(7, num_keywords // 2)}ê°œ

        3. **ë§¥ë½ í‚¤ì›Œë“œ (Context Keywords)**: 
           - ê´€ë ¨ ê·œì œ, í‘œì¤€, ì •ì±…, ì»´í”Œë¼ì´ì–¸ìŠ¤
           - ì‚°ì—…ë³„ ì ìš© ì‚¬ë¡€, ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
           - ê²½ìŸ ê¸°ìˆ , ëŒ€ì²´ ì†”ë£¨ì…˜, ë¯¸ë˜ ì „ë§
           - {max(4, num_keywords // 3)}~{min(7, num_keywords // 2)}ê°œ

        **ìƒì„± ê·œì¹™:**
        - ê° í‚¤ì›Œë“œëŠ” ì‹¤ì œ ë‰´ìŠ¤ë‚˜ ê¸°ìˆ  ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ìš©ì–´ì—¬ì•¼ í•¨
        - ë‹¨ìˆœ ë²ˆì—­ì´ë‚˜ ë™ì˜ì–´ ë°˜ë³µ ê¸ˆì§€
        - ì•½ì–´ëŠ” ì—…ê³„ì—ì„œ ë” ë§ì´ ì“°ì´ëŠ” í˜•íƒœ í•˜ë‚˜ë§Œ ì„ íƒ
        - ê°€ëŠ¥í•œ í•œ ìµœì‹  ë²„ì „, ìµœì‹  í‘œì¤€, ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜"""

        if context:
            base_prompt += f"\n\n**ì¶”ê°€ ë§¥ë½**: {context}"

        base_prompt += """

        **ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ìœ íš¨í•œ JSONìœ¼ë¡œë§Œ ì‘ë‹µ):**
        {
            "primary_keywords": ["í•µì‹¬ ê¸°ìˆ ê³¼ í”Œë«í¼"],
            "related_terms": ["êµ¬ì²´ì  ì œí’ˆê³¼ ë„êµ¬ëª…"],
            "context_keywords": ["ì‚°ì—… ë™í–¥ê³¼ ì ìš© ë¶„ì•¼"],
            "confidence": 0.9
        }"""

        return base_prompt

    async def _call_llm(self, prompt: str) -> str:
        """LLM API í˜¸ì¶œ"""
        for attempt in range(self.max_retries):
            try:
                logger.debug(f"LLM API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}")
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” IT ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    timeout=self.timeout
                )
                content = response.choices[0].message.content
                if not content:
                    raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return content.strip()
            except AuthenticationError as e:
                logger.error(f"OpenAI ì¸ì¦ ì˜¤ë¥˜: {e.message}")
                raise ValueError("OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.") from e
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"LLM API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {error_msg}")
                if attempt == self.max_retries - 1:
                    if "429" in error_msg or "rate limit" in error_msg.lower():
                        raise ValueError("API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                    elif "quota" in error_msg.lower():
                        raise ValueError("OpenAI í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    else:
                        raise ValueError(f"LLM API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {error_msg}")
                await asyncio.sleep(2 ** attempt)
        raise ValueError("ëª¨ë“  ì¬ì‹œë„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


    def _parse_response(self, topic: str, raw_response: str, generation_time: float) -> KeywordResult:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ KeywordResultë¡œ ë³€í™˜"""
        try:
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', raw_response, re.DOTALL)
            if not json_match:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            data = json.loads(json_match.group())

            # [ìˆ˜ì •ë¨] 'synonyms' í•„ë“œ ì œê±°
            required_fields = ['primary_keywords', 'related_terms', 'context_keywords']
            if not all(field in data for field in required_fields):
                raise ValueError(f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {required_fields}")

            primary_keywords = self._clean_keywords(data.get('primary_keywords', []))
            related_terms = self._clean_keywords(data.get('related_terms', []))
            context_keywords = self._clean_keywords(data.get('context_keywords', []))
            confidence_score = min(1.0, max(0.0, float(data.get('confidence', 0.8))))

            if not primary_keywords:
                primary_keywords = [topic]
                confidence_score = 0.5

            return KeywordResult(
                topic=topic,
                primary_keywords=primary_keywords,
                related_terms=related_terms,
                context_keywords=context_keywords,
                confidence_score=confidence_score,
                generation_time=generation_time,
                raw_response=raw_response
            )
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_fallback_result(topic, raw_response, generation_time)

    def _clean_keywords(self, keywords: List[Any]) -> List[str]:
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ì œí•©ë‹ˆë‹¤."""
        if not isinstance(keywords, list):
            logger.warning(f"í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(keywords)}")
            return []

        cleaned = []
        for keyword in keywords:
            if isinstance(keyword, str):
                keyword = keyword.strip().strip('"\'')
                if len(keyword) > 1:
                    cleaned.append(keyword)

        seen = set()
        unique_keywords = []
        for keyword in cleaned:
            lower_keyword = keyword.lower()
            if lower_keyword not in seen:
                seen.add(lower_keyword)
                unique_keywords.append(keyword)
        return unique_keywords[:12]

    def _create_fallback_result(self, topic: str, raw_response: str, generation_time: float) -> KeywordResult:
        """íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í‚¤ì›Œë“œ ê²°ê³¼ ìƒì„±"""
        logger.warning("íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± í‚¤ì›Œë“œ ìƒì„±")
        basic_keywords = [topic.strip()]
        words = topic.split()
        if len(words) > 1:
            basic_keywords.extend([word.strip() for word in words if len(word.strip()) > 1])

        basic_keywords = list(dict.fromkeys(basic_keywords))

        return KeywordResult(
            topic=topic,
            primary_keywords=basic_keywords,
            related_terms=[],
            context_keywords=[],
            confidence_score=0.2,
            generation_time=generation_time,
            raw_response=raw_response
        )

    def get_all_keywords(self, result: KeywordResult) -> List[str]:
        """[ìˆ˜ì •ë¨] ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        all_keywords = (result.primary_keywords + result.related_terms + result.context_keywords)
        return list(dict.fromkeys(all_keywords))

    def format_keywords_summary(self, result: KeywordResult) -> str:
        """í‚¤ì›Œë“œ ê²°ê³¼ë¥¼ ìš”ì•½ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        total_count = len(self.get_all_keywords(result))
        confidence_percent = int(result.confidence_score * 100)

        summary = (f"**í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ** (ì£¼ì œ: {result.topic})\n"
                   f"ğŸ“Š ì´ {total_count}ê°œ í‚¤ì›Œë“œ | ì‹ ë¢°ë„: {confidence_percent}% | ì†Œìš”ì‹œê°„: {result.generation_time:.1f}ì´ˆ\n\n")

        if result.primary_keywords:
            keywords_str = ', '.join(result.primary_keywords[:5])
            extra_count = len(result.primary_keywords) - 5
            summary += f"ğŸ¯ **í•µì‹¬**: {keywords_str}"
            if extra_count > 0:
                summary += f" ì™¸ {extra_count}ê°œ"
            summary += "\n"

        if result.related_terms:
            keywords_str = ', '.join(result.related_terms[:4])
            extra_count = len(result.related_terms) - 4
            summary += f"ğŸ”— **ê´€ë ¨**: {keywords_str}"
            if extra_count > 0:
                summary += f" ì™¸ {extra_count}ê°œ"
            summary += "\n"
        return summary

def create_keyword_generator(api_key: Optional[str] = None, model: Optional[str] = None) -> KeywordGenerator:
    """í‚¤ì›Œë“œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return KeywordGenerator(api_key=api_key, model=model)

async def generate_keywords_for_topic(topic: str, context: Optional[str] = None) -> KeywordResult:
    """ì£¼ì œì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    generator = create_keyword_generator()
    return await generator.generate_keywords(topic, context)

if __name__ == "__main__":
    print("ğŸ§ª í‚¤ì›Œë“œ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸")
    print("pytestë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("pytest tests/test_keyword_generator.py -v")