"""
í‚¤ì›Œë“œ ìƒì„± ëª¨ë“ˆ
- LLM(OpenAI)ì„ í™œìš©í•˜ì—¬ ì£¼ì œ ê¸°ë°˜ í‚¤ì›Œë“œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
- ìƒì„±ëœ í‚¤ì›Œë“œëŠ” ì´ìŠˆ ëª¨ë‹ˆí„°ë§, ê²€ìƒ‰ ìµœì í™”, ë¶„ì„ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
"""

import asyncio
import json
import re
import time
from typing import List, Optional, Any
from dataclasses import dataclass
from loguru import logger

try:
    from openai import AsyncOpenAI, AuthenticationError
except ImportError:
    logger.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    class AsyncOpenAI: pass  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ ì‹œ ë”ë¯¸ í´ë˜ìŠ¤ ì •ì˜
    class AuthenticationError(Exception): pass  # ë”ë¯¸ ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜

from src.config import config  # í™˜ê²½ ì„¤ì • ë¡œë“œ
from src.models import KeywordResult  # ì¤‘ì•™ ë°ì´í„° ëª¨ë¸ import


@dataclass
class KeywordResult:
    """í‚¤ì›Œë“œ ìƒì„± ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤.

    Attributes:
        topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ì´ ë˜ëŠ” ì£¼ì œ.
        primary_keywords (List[str]): ì£¼ì œì˜ ë³¸ì§ˆì„ í¬ì°©í•˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œ.
        related_terms (List[str]): ê³ ìœ ëª…ì‚¬, ì œí’ˆëª…, ìµœì‹  ìš©ì–´ ë“± ê´€ë ¨ ìš©ì–´.
        context_keywords (List[str]): ì£¼ì œì˜ ì‚°ì—…, ì •ì±…, ì‚¬íšŒì  ë§¥ë½ ê´€ë ¨ í‚¤ì›Œë“œ.
        confidence_score (float): ìƒì„±ëœ í‚¤ì›Œë“œì˜ ì‹ ë¢°ë„ ì ìˆ˜ (0.0 ~ 1.0).
        generation_time (float): í‚¤ì›Œë“œ ìƒì„±ì— ì†Œìš”ëœ ì‹œê°„ (ì´ˆ).
        raw_response (str): LLMì˜ ì›ë³¸ ì‘ë‹µ ë°ì´í„°.
    """
    topic: str
    primary_keywords: List[str]
    related_terms: List[str]
    context_keywords: List[str]
    confidence_score: float
    generation_time: float
    raw_response: str


class KeywordGenerator:
    """OpenAI LLMì„ í™œìš©í•œ í‚¤ì›Œë“œ ìƒì„± í´ë˜ìŠ¤.

    ì£¼ì œì™€ ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        """KeywordGenerator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            api_key (Optional[str]): OpenAI API í‚¤. Noneì¼ ê²½ìš° í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ.
            model (Optional[str]): ì‚¬ìš©í•  LLM ëª¨ë¸. Noneì¼ ê²½ìš° ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©.

        Raises:
            ValueError: API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš°.
        """
        self.api_key = api_key or config.get_openai_api_key()
        self.model = model or config.get_openai_model()

        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.max_retries = config.get_max_retry_count()  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        self.timeout = config.get_keyword_generation_timeout()  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
        self.temperature = config.get_openai_temperature()  # LLM ì‘ë‹µ ë‹¤ì–‘ì„± ì¡°ì ˆ
        self.max_tokens = config.get_openai_max_tokens()  # ìµœëŒ€ í† í° ìˆ˜
        logger.info(f"KeywordGenerator ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model})")

    async def generate_keywords(
        self,
        topic: str,
        context: Optional[str] = None,
        num_keywords: int = 50
    ) -> KeywordResult:
        """ì£¼ì œì™€ ì„ íƒì  ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ ì£¼ì œ.
            context (Optional[str]): ì£¼ì œì— ëŒ€í•œ ì¶”ê°€ ë§¥ë½ ì •ë³´.
            num_keywords (int): ìƒì„±í•  í‚¤ì›Œë“œì˜ ëª©í‘œ ê°œìˆ˜. ê¸°ë³¸ê°’ì€ 50.

        Returns:
            KeywordResult: ìƒì„±ëœ í‚¤ì›Œë“œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ ê²°ê³¼ ê°ì²´.

        Raises:
            ValueError: ì£¼ì œê°€ ë¹„ì–´ ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš°.
            Exception: LLM í˜¸ì¶œ ë˜ëŠ” ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ.
        """
        start_time = time.time()
        logger.info(f"í‚¤ì›Œë“œ ìƒì„± ì‹œì‘: '{topic}' (ëª¨ë¸: {self.model})")

        if not topic or not topic.strip():
            raise ValueError("ì£¼ì œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

        topic = topic.strip()

        try:
            # 1. LLMì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(topic, context, num_keywords)

            # 2. LLM í˜¸ì¶œë¡œ ì›ë³¸ ì‘ë‹µ ìˆ˜ì§‘
            raw_response = await self._call_llm(prompt)

            # 3. ì‘ë‹µ íŒŒì‹± ë° ê²°ê³¼ ê°ì²´ ìƒì„±
            keyword_result = self._parse_response(topic, raw_response, time.time() - start_time)

            logger.success(
                f"í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ: {len(keyword_result.primary_keywords)}ê°œ í•µì‹¬ í‚¤ì›Œë“œ, "
                f"ì‹ ë¢°ë„ {keyword_result.confidence_score:.2f}, "
                f"ì†Œìš”ì‹œê°„ {keyword_result.generation_time:.1f}ì´ˆ"
            )
            return keyword_result
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def _build_prompt(self, topic: str, context: Optional[str], num_keywords: int) -> str:
        """LLMì— ì „ë‹¬í•  í‚¤ì›Œë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

        ì „ë¬¸ì ì´ê³  ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ë„ë¡ ìƒì„¸í•œ ì§€ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.

        Args:
            topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ ì£¼ì œ.
            context (Optional[str]): ì¶”ê°€ ë§¥ë½ ì •ë³´.
            num_keywords (int): ìƒì„±í•  í‚¤ì›Œë“œì˜ ëª©í‘œ ê°œìˆ˜.

        Returns:
            str: êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´.
        """
        base_prompt = f"""ì£¼ì œ "{topic}"ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì‹¬ì¸µì ì¸ ì´ìŠˆ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ê³ í’ˆì§ˆ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ëª©ì **: ìƒì„±ëœ í‚¤ì›Œë“œëŠ” ìµœì‹  ë‰´ìŠ¤, ê¸°ìˆ  ë¬¸ì„œ, ì—°êµ¬ ë…¼ë¬¸, ì—…ê³„ ë³´ê³ ì„œì—ì„œ í•´ë‹¹ ì£¼ì œì™€ ê´€ë ¨ëœ ê°€ì¥ ì¤‘ìš”í•˜ê³  ì‹œì˜ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

**í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ìƒì„¸ ì„¤ëª…:**

1. **í•µì‹¬ í‚¤ì›Œë“œ (Primary Keywords)** - {max(5, num_keywords // 3)}~{min(10, num_keywords // 2)}ê°œ:
   - ì£¼ì œì˜ ë³¸ì§ˆì„ ì •í™•íˆ í¬ì°©í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ì „ë¬¸ ìš©ì–´
   - í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ê°€ë“¤ì´ ì¼ìƒì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ ìš©ì–´
   - í•™ìˆ  ë…¼ë¬¸, ê¸°ìˆ  ë¬¸ì„œ, ì—…ê³„ ë¦¬í¬íŠ¸ì˜ ì œëª©ì´ë‚˜ í‚¤ì›Œë“œ ì„¹ì…˜ì— ìì£¼ ë“±ì¥í•˜ëŠ” ìš©ì–´
   - ê²€ìƒ‰ ì—”ì§„ì—ì„œ ë†’ì€ ì •í™•ë„ë¡œ ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” êµ¬ë³„ë ¥ ìˆëŠ” ìš©ì–´
   - ì•½ì–´ì™€ ì „ì²´ ëª…ì¹­ ì¤‘ ì—…ê³„ì—ì„œ ë” ë³´í¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í˜•íƒœ ì„ íƒ

2. **ê´€ë ¨ ìš©ì–´ (Related Terms)** - {max(5, num_keywords // 3)}~{min(10, num_keywords // 2)}ê°œ:
   - êµ¬ì²´ì ì´ê³  ì‹¤ì²´ê°€ ìˆëŠ” ê³ ìœ ëª…ì‚¬ (ì œí’ˆëª…, ì„œë¹„ìŠ¤ëª…, í”Œë«í¼ëª…, ë„êµ¬ëª…)
   - í•´ë‹¹ ë¶„ì•¼ì˜ ì£¼ìš” í”Œë ˆì´ì–´ (ê¸°ì—…, ê¸°ê´€, ë‹¨ì²´, ì €ëª…í•œ ì¸ë¬¼, ì—°êµ¬ ê·¸ë£¹)
   - êµ¬ì²´ì ì¸ ê¸°ìˆ  ì‚¬ì–‘, ë²„ì „, ëª¨ë¸ëª…, í‘œì¤€ ê·œê²© ë²ˆí˜¸
   - ìµœê·¼ 1-2ë…„ ë‚´ ë“±ì¥í•˜ê±°ë‚˜ ì£¼ëª©ë°›ëŠ” ì‹ ê·œ ìš©ì–´, ì‹ ì¡°ì–´, íŠ¸ë Œë“œ
   - ê²½ìŸ ê¸°ìˆ , ëŒ€ì²´ ì†”ë£¨ì…˜, ìœ ì‚¬ ì ‘ê·¼ë²•ì˜ êµ¬ì²´ì  ëª…ì¹­
   - ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ëª…, í”„ë ˆì„ì›Œí¬, ë¼ì´ë¸ŒëŸ¬ë¦¬, API ëª…ì¹­

3. **ë§¥ë½ í‚¤ì›Œë“œ (Context Keywords)** - {max(5, num_keywords // 3)}~{min(10, num_keywords // 2)}ê°œ:
   - ì£¼ì œê°€ ì†í•œ ë” ë„“ì€ ì‚°ì—…, í•™ë¬¸ ë¶„ì•¼, ì‚¬íšŒì  ì˜ì—­
   - ê´€ë ¨ ë²•ê·œ, ì •ì±…, í‘œì¤€, ì¸ì¦, ì»´í”Œë¼ì´ì–¸ìŠ¤ ìš©ì–´
   - ì£¼ì œê°€ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‹¤ë¥¸ ë¶„ì•¼ë‚˜ ì‚°ì—… (êµì°¨ì , ìœµí•© ì˜ì—­)
   - ì§€ì •í•™ì  ë§¥ë½, ì§€ì—­ë³„ íŠ¹ì„±, ê¸€ë¡œë²Œ vs ë¡œì»¬ ì´ìŠˆ
   - ì‹œê°„ì  ë§¥ë½ (ê³¼ê±° ë°°ê²½, í˜„ì¬ ìƒí™©, ë¯¸ë˜ ì „ë§ê³¼ ê´€ë ¨ëœ ìš©ì–´)
   - ì‚¬íšŒì  ì˜í–¥, ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­, ì§€ì†ê°€ëŠ¥ì„± ê´€ë ¨ ìš©ì–´

**í‚¤ì›Œë“œ ìƒì„± ìƒì„¸ ì§€ì¹¨:**

1. **êµ¬ì²´ì„±ê³¼ ê²€ìƒ‰ê°€ëŠ¥ì„±**:
   - ì¶”ìƒì ì´ê³  ì¼ë°˜ì ì¸ ìš©ì–´ëŠ” í”¼í•˜ê³ , ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢í ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ìš©ì–´ ì‚¬ìš©
   - "ê¸°ìˆ ", "ì‹œìŠ¤í…œ", "ì†”ë£¨ì…˜" ê°™ì€ ë²”ìš©ì–´ë³´ë‹¤ëŠ” ì •í™•í•œ ëª…ì¹­ê³¼ ê³ ìœ ëª…ì‚¬ ì„ í˜¸
   - ê°€ëŠ¥í•œ ê²½ìš° ë²„ì „ ë²ˆí˜¸, ì—°ë„, ì„¸ëŒ€ ì •ë³´ í¬í•¨ (ì˜ˆ: 5G, Wi-Fi 6E, USB 4.0)

2. **ì‹œì˜ì„±ê³¼ ìµœì‹ ì„±**:
   - 2023-2024ë…„ì— ë“±ì¥í–ˆê±°ë‚˜ ì£¼ëª©ë°›ëŠ” ìµœì‹  ìš©ì–´ ìš°ì„  í¬í•¨
   - í•´ë‹¹ ë¶„ì•¼ì˜ ìµœê·¼ ì£¼ìš” ì´ë²¤íŠ¸, ë°œí‘œ, ì¶œì‹œì™€ ê´€ë ¨ëœ ìš©ì–´
   - í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë…¼ìŸ, ì´ìŠˆ, íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ëŠ” í‚¤ì›Œë“œ

3. **ì „ë¬¸ì„±ê³¼ ê¹Šì´**:
   - í•´ë‹¹ ë¶„ì•¼ ì…ë¬¸ìê°€ ì•„ë‹Œ ì „ë¬¸ê°€ë‚˜ ì—°êµ¬ìê°€ ì‚¬ìš©í•  ë²•í•œ ìš©ì–´
   - í‘œë©´ì  ì´í•´ê°€ ì•„ë‹Œ ì‹¬ì¸µì  ë¶„ì„ì— í•„ìš”í•œ ê¸°ìˆ ì  ìš©ì–´
   - í•™ìˆ  ë°ì´í„°ë² ì´ìŠ¤, íŠ¹í—ˆ ê²€ìƒ‰, ê¸°ìˆ  í¬ëŸ¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì „ë¬¸ ìš©ì–´

4. **ë‹¤ì–‘ì„±ê³¼ í¬ê´„ì„±**:
   - ì£¼ì œì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì»¤ë²„í•  ìˆ˜ ìˆë„ë¡ í‚¤ì›Œë“œ êµ¬ì„±
   - ê¸°ìˆ ì , ë¹„ì¦ˆë‹ˆìŠ¤ì , ì‚¬íšŒì , ì •ì±…ì  ê´€ì ì„ ëª¨ë‘ í¬í•¨
   - ê¸ì •ì  ì¸¡ë©´ê³¼ ë¶€ì •ì  ì¸¡ë©´(ìœ„í—˜, í•œê³„, ë¹„íŒ) ëª¨ë‘ ê³ ë ¤

5. **ì–¸ì–´ ì„ íƒ ê¸°ì¤€**:
   - í•œêµ­ì–´/ì˜ì–´ëŠ” í•´ë‹¹ ìš©ì–´ê°€ ì‹¤ì œë¡œ ë” ë§ì´ ì‚¬ìš©ë˜ëŠ” í˜•íƒœë¡œ ì„ íƒ
   - êµ­ì œ í‘œì¤€ì´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì›ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - í•œêµ­ íŠ¹ìœ ì˜ ë§¥ë½ì´ë‚˜ ìš©ì–´ê°€ ìˆë‹¤ë©´ í¬í•¨
"""

        if context:
            base_prompt += f"\n\n**ì¶”ê°€ ë§¥ë½ ì •ë³´**: {context}"

        base_prompt += """

**í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- ê° í‚¤ì›Œë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ”ê°€?
- ë‹¨ìˆœ ë™ì˜ì–´ë‚˜ ë²ˆì—­ì´ ì•„ë‹Œ ê³ ìœ í•œ ê°€ì¹˜ë¥¼ ê°€ì§„ í‚¤ì›Œë“œì¸ê°€?
- ì‹¤ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì´ë‚˜ ë…¼ë¬¸ ì œëª©ì— ë“±ì¥í•  ë²•í•œ ìš©ì–´ì¸ê°€?
- 2024ë…„ í˜„ì¬ ì‹œì ì—ì„œ ì—¬ì „íˆ ìœ íš¨í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ìš©ì–´ì¸ê°€?

**ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ìœ íš¨í•œ JSONìœ¼ë¡œë§Œ ì‘ë‹µ):**
{
    "primary_keywords": ["ì£¼ì œì˜ í•µì‹¬ì„ ë‚˜íƒ€ë‚´ëŠ” ì „ë¬¸ ìš©ì–´ë“¤"],
    "related_terms": ["êµ¬ì²´ì ì¸ ì œí’ˆ/ì„œë¹„ìŠ¤/ì¡°ì§ëª… ë“± ê³ ìœ ëª…ì‚¬ë“¤"],
    "context_keywords": ["ë” ë„“ì€ ë§¥ë½ê³¼ ê´€ë ¨ ë¶„ì•¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìš©ì–´ë“¤"],
    "confidence": 0.85
}

ì£¼ì˜: ë°˜ë“œì‹œ ì‹¤ì¬í•˜ê³  ê²€ì¦ ê°€ëŠ¥í•œ ìš©ì–´ë§Œ ìƒì„±í•˜ì„¸ìš”. ì¶”ì¸¡ì´ë‚˜ ì°½ì‘ì€ ê¸ˆì§€ë©ë‹ˆë‹¤."""

        return base_prompt

    async def _call_llm(self, prompt: str) -> str:
        """OpenAI LLM APIë¥¼ í˜¸ì¶œí•˜ì—¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        GPT-4o ëª¨ë¸ì— ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•˜ë©°, ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.

        Args:
            prompt (str): LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸.

        Returns:
            str: LLMì˜ ì›ë³¸ ì‘ë‹µ ë¬¸ìì—´.

        Raises:
            ValueError: API ì¸ì¦ ì‹¤íŒ¨, ì‚¬ìš©ëŸ‰ ì´ˆê³¼, í¬ë ˆë”§ ë¶€ì¡± ë“±ìœ¼ë¡œ ìµœì¢… ì‹¤íŒ¨ ì‹œ.
        """
        for attempt in range(self.max_retries):
            try:
                logger.debug(f"LLM API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}")

                # ê¸°ë³¸ ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •
                request_params = {
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” IT ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": self.temperature,
                    "max_tokens": self.max_tokens,
                    "timeout": self.timeout
                }

                # GPT-4o ëª¨ë¸ì¼ ê²½ìš° ì¶”ê°€ ìµœì í™” íŒŒë¼ë¯¸í„° ì ìš©
                if self.model == "gpt-4o":
                    request_params.update({
                        "frequency_penalty": 0.3,  # ë°˜ë³µëœ ë‹¨ì–´ ì‚¬ìš© ì–µì œ
                        "presence_penalty": 0.3,  # ìƒˆë¡œìš´ ì£¼ì œ íƒìƒ‰ ì¥ë ¤
                        "response_format": {"type": "json_object"}  # JSON ì¶œë ¥ ê°•ì œ
                    })
                    logger.debug("GPT-4o ìµœì í™” íŒŒë¼ë¯¸í„° ì ìš©")

                # API í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
                response = await self.client.chat.completions.create(**request_params)
                content = response.choices[0].message.content
                if not content:
                    raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return content.strip()

            except AuthenticationError as e:
                logger.error(f"OpenAI ì¸ì¦ ì˜¤ë¥˜: {e}")
                raise ValueError("OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.") from e
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"LLM API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {error_msg}")
                if attempt == self.max_retries - 1:
                    if "429" in error_msg or "rate limit" in error_msg.lower():
                        raise ValueError("API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                    elif "quota" in error_msg.lower():
                        raise ValueError("OpenAI í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                    else:
                        raise ValueError(f"LLM API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {error_msg}")
                await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„

    def _parse_response(self, topic: str, raw_response: str, generation_time: float) -> KeywordResult:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ KeywordResult ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ ì£¼ì œ.
            raw_response (str): LLMì˜ ì›ë³¸ ì‘ë‹µ.
            generation_time (float): í‚¤ì›Œë“œ ìƒì„±ì— ì†Œìš”ëœ ì‹œê°„.

        Returns:
            KeywordResult: íŒŒì‹±ëœ í‚¤ì›Œë“œ ê²°ê³¼ ê°ì²´.

        Raises:
            ValueError: ì‘ë‹µì— ìœ íš¨í•œ JSONì´ ì—†ê±°ë‚˜ í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš°.
        """
        try:
            # JSON ê°ì²´ ì¶”ì¶œ
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', raw_response, re.DOTALL)
            if not json_match:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            data = json.loads(json_match.group())

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['primary_keywords', 'related_terms', 'context_keywords']
            if not all(field in data for field in required_fields):
                raise ValueError(f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {required_fields}")

            # í‚¤ì›Œë“œ ì •ì œ ë° ì¤‘ë³µ ì œê±°
            primary_keywords = self._clean_keywords(data.get('primary_keywords', []))
            related_terms = self._clean_keywords(data.get('related_terms', []))
            context_keywords = self._clean_keywords(data.get('context_keywords', []))
            confidence_score = min(1.0, max(0.0, float(data.get('confidence', 0.8))))

            # í•µì‹¬ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì£¼ì œë¥¼ ê¸°ë³¸ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
            if not primary_keywords:
                primary_keywords = [topic]
                confidence_score = 0.5

            return KeywordResult(
                topic=topic,
                primary_keywords=primary_keywords,
                related_terms=related_terms,
                context_keywords=context_keywords,
                confidence_score=confidence_score,
                generation_time=generation_time,
                raw_response=raw_response
            )
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_fallback_result(topic, raw_response, generation_time)

    def _clean_keywords(self, keywords: List[Any]) -> List[str]:
        """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

        Args:
            keywords (List[Any]): ì •ì œí•  ì›ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸.

        Returns:
            List[str]: ì •ì œëœ ê³ ìœ  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 12ê°œ).
        """
        if not isinstance(keywords, list):
            logger.warning(f"í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(keywords)}")
            return []

        cleaned = []
        for keyword in keywords:
            if isinstance(keyword, str):
                keyword = keyword.strip().strip('"\'')
                if len(keyword) > 1:  # ë„ˆë¬´ ì§§ì€ í‚¤ì›Œë“œ ì œì™¸
                    cleaned.append(keyword)

        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì¤‘ë³µ ì œê±°
        seen = set()
        unique_keywords = []
        for keyword in cleaned:
            lower_keyword = keyword.lower()
            if lower_keyword not in seen:
                seen.add(lower_keyword)
                unique_keywords.append(keyword)
        return unique_keywords[:12]  # ìµœëŒ€ 12ê°œë¡œ ì œí•œ

    def _create_fallback_result(self, topic: str, raw_response: str, generation_time: float) -> KeywordResult:
        """ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ ì£¼ì œ.
            raw_response (str): LLMì˜ ì›ë³¸ ì‘ë‹µ.
            generation_time (float): í‚¤ì›Œë“œ ìƒì„±ì— ì†Œìš”ëœ ì‹œê°„.

        Returns:
            KeywordResult: ê¸°ë³¸ í‚¤ì›Œë“œì™€ ë‚®ì€ ì‹ ë¢°ë„ë¥¼ í¬í•¨í•œ ê²°ê³¼ ê°ì²´.
        """
        logger.warning("íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± í‚¤ì›Œë“œ ìƒì„±")
        basic_keywords = [topic.strip()]
        words = topic.split()
        if len(words) > 1:
            basic_keywords.extend([word.strip() for word in words if len(word.strip()) > 1])

        basic_keywords = list(dict.fromkeys(basic_keywords))

        return KeywordResult(
            topic=topic,
            primary_keywords=basic_keywords,
            related_terms=[],
            context_keywords=[],
            confidence_score=0.2,
            generation_time=generation_time,
            raw_response=raw_response
        )

    def get_all_keywords(self, result: KeywordResult) -> List[str]:
        """ëª¨ë“  í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë¥¼ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê²°í•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            result (KeywordResult): í‚¤ì›Œë“œ ê²°ê³¼ ê°ì²´.

        Returns:
            List[str]: ì¤‘ë³µ ì œê±°ëœ ì „ì²´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸.
        """
        all_keywords = (result.primary_keywords + result.related_terms + result.context_keywords)
        return list(dict.fromkeys(all_keywords))

    def format_keywords_summary(self, result: KeywordResult) -> str:
        """í‚¤ì›Œë“œ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ ìš”ì•½ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

        Args:
            result (KeywordResult): ìš”ì•½í•  í‚¤ì›Œë“œ ê²°ê³¼ ê°ì²´.

        Returns:
            str: í¬ë§·íŒ…ëœ ìš”ì•½ ë¬¸ìì—´.
        """
        total_count = len(self.get_all_keywords(result))
        confidence_percent = int(result.confidence_score * 100)

        summary = (f"**í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ** (ì£¼ì œ: {result.topic})\n"
                   f"ğŸ“Š ì´ {total_count}ê°œ í‚¤ì›Œë“œ | ì‹ ë¢°ë„: {confidence_percent}% | ì†Œìš”ì‹œê°„: {result.generation_time:.1f}ì´ˆ\n\n")

        if result.primary_keywords:
            keywords_str = ', '.join(result.primary_keywords[:5])
            extra_count = len(result.primary_keywords) - 5
            summary += f"ğŸ¯ **í•µì‹¬**: {keywords_str}"
            if extra_count > 0:
                summary += f" ì™¸ {extra_count}ê°œ"
            summary += "\n"

        if result.related_terms:
            keywords_str = ', '.join(result.related_terms[:4])
            extra_count = len(result.related_terms) - 4
            summary += f"ğŸ”— **ê´€ë ¨**: {keywords_str}"
            if extra_count > 0:
                summary += f" ì™¸ {extra_count}ê°œ"
            summary += "\n"
        return summary


def create_keyword_generator(api_key: Optional[str] = None, model: Optional[str] = None) -> KeywordGenerator:
    """KeywordGenerator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜.

    Args:
        api_key (Optional[str]): OpenAI API í‚¤. Noneì¼ ê²½ìš° í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ.
        model (Optional[str]): ì‚¬ìš©í•  LLM ëª¨ë¸. Noneì¼ ê²½ìš° ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©.

    Returns:
        KeywordGenerator: ì´ˆê¸°í™”ëœ KeywordGenerator ì¸ìŠ¤í„´ìŠ¤.
    """
    return KeywordGenerator(api_key=api_key, model=model)


async def generate_keywords_for_topic(topic: str, context: Optional[str] = None) -> KeywordResult:
    """ì£¼ì œì— ëŒ€í•œ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” ê³ ìˆ˜ì¤€ ë˜í¼ í•¨ìˆ˜.

    Args:
        topic (str): í‚¤ì›Œë“œ ìƒì„±ì˜ ê¸°ë°˜ ì£¼ì œ.
        context (Optional[str]): ì¶”ê°€ ë§¥ë½ ì •ë³´.

    Returns:
        KeywordResult: ìƒì„±ëœ í‚¤ì›Œë“œ ê²°ê³¼ ê°ì²´.
    """
    generator = create_keyword_generator()
    return await generator.generate_keywords(topic, context)


if __name__ == "__main__":
    print("ğŸ§ª í‚¤ì›Œë“œ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸")
    print("pytestë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("pytest tests/test_keyword_generator.py -v")